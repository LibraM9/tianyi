{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "collapsed": false,
    "id": "EFF7AE5565434FBA8FC6335A90115716"
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录\n",
    "!ls /home/kesci/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "collapsed": false,
    "id": "25282EC4672B4D3C84813CE3DC37065C"
   },
   "outputs": [],
   "source": [
    "# 查看个人持久化工作区文件\n",
    "!ls /home/kesci/work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "collapsed": false,
    "id": "48D19DD15D0E41069FED616C6959E745"
   },
   "outputs": [],
   "source": [
    "# 查看当前kernerl下的package\n",
    "!pip list --format=columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "collapsed": false,
    "id": "E6D96BC48FF94332B118CB5388F970E7"
   },
   "outputs": [],
   "source": [
    "# 显示cell运行时长\n",
    "%load_ext klab-autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "797D2D9FB1264A8BA9EB58BB683695FC",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "D3688DAFDD39467683C753AD7109F331",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,log_loss,roc_auc_score\n",
    "from math import log10\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import skew, kurtosis\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "630DB63A0D5D41768B31F671F11456ED",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "data_path = '/home/kesci/input/smart_edu7557/'\n",
    "feature_path = '/home/kesci/work/feature/'\n",
    "out_path = '/home/kesci/work/out/'\n",
    "all_knowledge = pd.read_csv(open(data_path + 'all_knowledge.csv',encoding='utf8'))\n",
    "course1_exams = pd.read_csv(open(data_path + 'course1_exams.csv',encoding='utf8'))#85,369 考点依次向后，最后为综合性考试\n",
    "course2_exams = pd.read_csv(open(data_path + 'course2_exams.csv',encoding='utf8')) #94,368\n",
    "course3_exams = pd.read_csv(open(data_path + 'course3_exams.csv',encoding='utf8'))#70，263\n",
    "course4_exams = pd.read_csv(open(data_path + 'course4_exams.csv',encoding='utf8'))#68,220\n",
    "course5_exams = pd.read_csv(open(data_path + 'course5_exams.csv',encoding='utf8'))#90,336\n",
    "course6_exams = pd.read_csv(open(data_path + 'course6_exams.csv',encoding='utf8'))#54,147\n",
    "course7_exams = pd.read_csv(open(data_path + 'course7_exams.csv',encoding='utf8'))#78,317\n",
    "course8_exams = pd.read_csv(open(data_path + 'course8_exams.csv',encoding='utf8'))#78,224\n",
    "train = pd.read_csv(open(data_path + 'exam_score.csv',encoding='utf8')) #共8门课 65500,4\n",
    "student = pd.read_csv(open(data_path + 'student.csv',encoding='utf8'))#500,2\n",
    "course = pd.read_csv(open(data_path + 'course.csv',encoding='utf8'))#8,2\n",
    "test = pd.read_csv(open(data_path + 'submission_s2.csv',encoding='utf8'))#8000,5\n",
    "exams = pd.DataFrame({\"exam_id\":[],\"level_1\":[],0:[],\"course\":[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FB2AF8108CF2407391B2D18ADE84A8B5",
    "mdEditEnable": false
   },
   "source": [
    "# 模型1：章节考试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "C1A7AC723A7A4DF8890F54335B571457",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n02\n03\n04\n05\n06\n07\n08\n09\n10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:107: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9):\n",
    "    s=0\n",
    "    exec(\"\"\"s = course{}_exams.set_index(\"exam_id\").stack().to_frame().reset_index()\"\"\".format(i))\n",
    "    exam_list = s[\"exam_id\"].drop_duplicates().values\n",
    "    s_temp = pd.DataFrame({\"exam_id\":exam_list,\"exam_time\":range(len(exam_list))})\n",
    "    s = s.merge(s_temp,how='left',on=\"exam_id\")\n",
    "    s[\"course\"] = \"course{}\".format(i)\n",
    "    exams = exams.append(s)\n",
    "\n",
    "exams = exams.rename(columns={0:\"score\"})\n",
    "# 合并所有和考试相关的信息\n",
    "exams = exams.merge(all_knowledge,how='left',left_on=[\"course\",\"level_1\"],right_on=[\"course\",\"knowledge_point\"])\n",
    "exams = exams.merge(course,how='left',on='course')\n",
    "exams[\"hardvalue\"] = exams[\"score\"]*exams[\"complexity\"]\n",
    "exams[\"rank\"] = exams.groupby(\"exam_id\")[\"score\"].rank(ascending=False,method='first')\n",
    "exams[\"score\"] = exams[\"score\"].replace(0,np.nan)\n",
    "#将所有考试信息归到一维\n",
    "agg = {\n",
    "    \"score\":[\"count\"],#考了几个知识点\n",
    "    \"hardvalue\":[\"sum\",\"max\"] #难度值、难度最高的知识点有多高\n",
    "}\n",
    "exams_group = exams.groupby([\"exam_id\",\"exam_time\",\"course\",\"course_class\"],as_index=False).agg(agg) #617,2\n",
    "exams_group.columns=[\"exam_id\",\"exam_time\",\"course\",\"course_class\",\"knowledge_cnt\",\"hardvalue_sum\",\"hardvalue_max\"]\n",
    "exams_group = exams_group.merge(exams.loc[exams[\"rank\"]==1][[\"exam_id\",\"section\",\"category\"]],how=\"left\",on=[\"exam_id\"])#本次考试的知识点所属领域\n",
    "exams_group = exams_group.sort_values(by=[\"course_class\",\"course\",\"exam_time\"]).reset_index(drop=True)\n",
    "\n",
    "#学生维度\n",
    "train[\"is_train\"]=1\n",
    "test[\"is_train\"]=0\n",
    "test.rename(columns = {'pred':'score'},inplace=True)\n",
    "data_all = train.append(test)\n",
    "data_all = data_all.merge(student,how='left',on='student_id')\n",
    "data_all = data_all.merge(exams_group,how='left',on=[\"exam_id\",\"course\"])\n",
    "data_all[\"effotvalue\"] = data_all[\"score\"]/data_all[\"hardvalue_sum\"]\n",
    "bin_labels = [0,1,2,3,4,5,6,7]\n",
    "data_all[\"hardvalue_rank\"]=pd.cut(data_all[\"hardvalue_sum\"], 8, right=True, labels=bin_labels, retbins=False, precision=3, include_lowest=False)\n",
    "#当前章节第几次考试,测试集中3/16次考试更换了知识点,category_rank为nan则说明为阶段性考试\n",
    "data_tmp = data_all.sort_values(by=[\"student_id\",\"course\",\"section\",\"knowledge_cnt\"])\n",
    "data_tmp = data_tmp.drop_duplicates([\"student_id\",\"course\",\"section\"])\n",
    "data_tmp[\"category_rank\"] = data_tmp.groupby([\"student_id\",\"course\",\"category\"])[\"exam_time\"].rank(method=\"first\")\n",
    "data_all = data_all.merge(data_tmp[[\"student_id\",\"course\",\"exam_time\",\"category_rank\"]],how='left',on=[\"student_id\",\"course\",\"exam_time\"])\n",
    "#当前数据输出\n",
    "# data_all.to_csv(feature_path + \"data0809.csv\", index=False)\n",
    "\n",
    "#聚合\n",
    "exam_his={\"course1\":18,\"course2\":21,\"course3\":14,\"course4\":14,\n",
    "          \"course5\":22,\"course6\":10,\"course7\":16,\"course8\":16}\n",
    "# exam_his={\"course1\":20,\"course2\":23,\"course3\":16,\"course4\":16,\n",
    "#           \"course5\":24,\"course6\":12,\"course7\":18,\"course8\":18} \n",
    "          \n",
    "data_all[\"exam_time_tmp\"] = data_all[\"course\"].replace(exam_his)\n",
    "data_all[\"exam_time01\"] =data_all[\"exam_time\"]-(0.1*data_all[\"exam_time_tmp\"]).astype(int)\n",
    "data_all[\"exam_time02\"] =data_all[\"exam_time\"]-(0.2*data_all[\"exam_time_tmp\"]).astype(int)\n",
    "data_all[\"exam_time03\"] =data_all[\"exam_time\"]-(0.3*data_all[\"exam_time_tmp\"]).astype(int)\n",
    "data_all[\"exam_time04\"] =data_all[\"exam_time\"]-(0.4*data_all[\"exam_time_tmp\"]).astype(int)\n",
    "data_all[\"exam_time05\"] =data_all[\"exam_time\"]-(0.5*data_all[\"exam_time_tmp\"]).astype(int)\n",
    "data_all[\"exam_time06\"] =data_all[\"exam_time\"]-(0.6*data_all[\"exam_time_tmp\"]).astype(int)\n",
    "data_all[\"exam_time07\"] =data_all[\"exam_time\"]-(0.7*data_all[\"exam_time_tmp\"]).astype(int)\n",
    "data_all[\"exam_time08\"] =data_all[\"exam_time\"]-(0.8*data_all[\"exam_time_tmp\"]).astype(int)\n",
    "data_all[\"exam_time09\"] =data_all[\"exam_time\"]-(0.9*data_all[\"exam_time_tmp\"]).astype(int)\n",
    "data_all[\"exam_time10\"] =data_all[\"exam_time\"]-(data_all[\"exam_time_tmp\"]).astype(int)\n",
    "\n",
    "#对历史努力值进行统计\n",
    "agg = {\n",
    "    \"score\":[\"mean\",\"median\",\"std\",\"max\",\"min\"],\n",
    "    \"category_his\":[\"count\"]\n",
    "    # \"score\":[\"mean\",\"median\",\"std\",\"max\",\"min\",'skew'],\n",
    "    # \"category_his\":[\"count\"],\n",
    "    # \"effotvalue\":[\"mean\",\"median\",\"std\",\"max\",\"min\",'skew']\n",
    "}\n",
    "for i in [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]:\n",
    "    print(i)\n",
    "    data_union = data_all[[\"student_id\",\"course\",\"exam_id\",\"exam_time\",\"exam_time{}\".format(i),\"category\"]]\\\n",
    "        .merge(data_all[[\"student_id\",\"course\",\"exam_time\",\"category\", \"effotvalue\",\"score\",\"hardvalue_sum\"]].rename(columns={\"exam_time\":\"exam_time_his\",\"category\":\"category_his\"}),\n",
    "               how='left',on=[\"student_id\",\"course\"])\n",
    "    data_union = data_union.loc[(data_union[\"exam_time\"+i]<data_union[\"exam_time_his\"])&(data_union[\"exam_time_his\"]<data_union[\"exam_time\"])]\n",
    "    data_union[\"score\"] = data_union[\"score\"].replace(0,np.nan) #将缺考的努力值置为空\n",
    "    data_tmp = data_union.groupby([\"student_id\",\"course\",\"exam_id\"],as_index=False).agg(agg)\n",
    "    data_tmp.columns = [j[0]+\"_\"+j[1]+i for j in data_tmp.columns ]\n",
    "    data_tmp.columns = [\"student_id\",\"course\",\"exam_id\"]+list(data_tmp.columns[3:])\n",
    "    #计算应该对几条数据做聚合，筛选数据不足的行,如：第二次考试仅可以获取第一次考试的信息，信息量少于0.5/0.7/1，故舍弃\n",
    "    data_tmp[\"cnt\"] = (data_tmp[\"course\"].replace(exam_his)*(int(i[0])+0.1*int(i[1]))).astype(int)-1\n",
    "    data_tmp = data_tmp.loc[data_tmp[\"category_his_count\"+i]==data_tmp[\"cnt\"]]\n",
    "    del data_tmp[\"cnt\"]\n",
    "    del data_tmp[\"category_his_count\"+i]\n",
    "    data_all = data_all.merge(data_tmp, how='left', on=[\"student_id\", \"course\", \"exam_id\"])\n",
    "    if i==\"10\":\n",
    "        #筛选近期考点属于同一大类的考试进行统计\n",
    "        data_tmp2 = data_union.loc[data_union[\"category\"]==data_union[\"category_his\"]]\n",
    "        data_tmp2 = data_tmp2.groupby([\"student_id\", \"course\", \"exam_id\"], as_index=False)[\"score\"].agg([\"mean\",\"median\",\"std\",\"max\",\"min\"])\n",
    "        data_tmp2 = data_tmp2.reset_index()\n",
    "        data_tmp2.columns = list(data_tmp2.columns[:3])+[\"his_category_\"+j for j in data_tmp2.columns[3:]]\n",
    "        data_all = data_all.merge(data_tmp2,how='left',on=[\"student_id\", \"course\", \"exam_id\"])\n",
    "        #近3次同类考试的分数和难度值\n",
    "        data_tmp2 = data_union.loc[data_union[\"category\"] == data_union[\"category_his\"]]\n",
    "        data_tmp2[\"his_rank\"]=data_tmp2.groupby([\"student_id\", \"course\", \"exam_id\"])[\"exam_time_his\"].rank(ascending=False,method='first')\n",
    "        for k in [1,2,3]:\n",
    "            data_tmp3 = data_tmp2.loc[data_tmp2.his_rank==k]\n",
    "            data_tmp3 = data_tmp3[[\"student_id\", \"course\", \"exam_id\",\"score\",\"hardvalue_sum\"]].rename(columns={\"score\":\"score_last{}\".format(k),\"hardvalue_sum\":\"hardvalue_last{}\".format(k)})\n",
    "            data_all=data_all.merge(data_tmp3,how='left',on=[\"student_id\", \"course\", \"exam_id\"])\n",
    "del data_all[\"exam_time_tmp\"],data_all[\"exam_time05\"],data_all[\"exam_time07\"],data_all[\"exam_time10\"]\n",
    "data_all.to_csv(feature_path+\"data_plus_score0825.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "736C07BA3C0E480084DBB617A65E2957",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308500, 87)\n(307899, 87)\n(168014, 87)\n['gender', 'exam_time', 'knowledge_cnt', 'category_rank', 'hardvalue_sum', 'hardvalue_max', 'hardvalue_rank', 'his_category_mean', 'his_category_median', 'his_category_std', 'his_category_max', 'his_category_min', 'le_course', 'le_course_class', 'le_category', 'score_mean05', 'score_median05', 'score_std05', 'score_max05', 'score_min05', 'score_mean07', 'score_median07', 'score_std07', 'score_max07', 'score_min07', 'score_last1', 'hardvalue_last1', 'score_last2', 'hardvalue_last2', 'score_last3', 'hardvalue_last3', 'score_mean10', 'score_median10', 'score_std10', 'score_max10', 'score_min10', 'exam_time01', 'score_mean01', 'score_median01', 'score_std01', 'score_max01', 'score_min01', 'exam_time03', 'score_mean03', 'score_median03', 'score_std03', 'score_max03', 'score_min03', 'term', 'is_midterm', 'is_final']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>course</th>\n      <th>exam_id</th>\n      <th>score</th>\n      <th>is_train</th>\n      <th>gender</th>\n      <th>exam_time</th>\n      <th>course_class</th>\n      <th>knowledge_cnt</th>\n      <th>hardvalue_sum</th>\n      <th>hardvalue_max</th>\n      <th>section</th>\n      <th>category</th>\n      <th>effotvalue</th>\n      <th>hardvalue_rank</th>\n      <th>category_rank</th>\n      <th>exam_time01</th>\n      <th>exam_time02</th>\n      <th>exam_time03</th>\n      <th>exam_time04</th>\n      <th>exam_time06</th>\n      <th>exam_time08</th>\n      <th>exam_time09</th>\n      <th>score_mean01</th>\n      <th>score_median01</th>\n      <th>score_std01</th>\n      <th>score_max01</th>\n      <th>score_min01</th>\n      <th>score_mean02</th>\n      <th>score_median02</th>\n      <th>score_std02</th>\n      <th>score_max02</th>\n      <th>score_min02</th>\n      <th>score_mean03</th>\n      <th>score_median03</th>\n      <th>score_std03</th>\n      <th>score_max03</th>\n      <th>score_min03</th>\n      <th>score_mean04</th>\n      <th>score_median04</th>\n      <th>score_std04</th>\n      <th>score_max04</th>\n      <th>score_min04</th>\n      <th>score_mean05</th>\n      <th>score_median05</th>\n      <th>score_std05</th>\n      <th>score_max05</th>\n      <th>score_min05</th>\n      <th>score_mean06</th>\n      <th>score_median06</th>\n      <th>score_std06</th>\n      <th>score_max06</th>\n      <th>score_min06</th>\n      <th>score_mean07</th>\n      <th>score_median07</th>\n      <th>score_std07</th>\n      <th>score_max07</th>\n      <th>score_min07</th>\n      <th>score_mean08</th>\n      <th>score_median08</th>\n      <th>score_std08</th>\n      <th>score_max08</th>\n      <th>score_min08</th>\n      <th>score_mean09</th>\n      <th>score_median09</th>\n      <th>score_std09</th>\n      <th>score_max09</th>\n      <th>score_min09</th>\n      <th>score_mean10</th>\n      <th>score_median10</th>\n      <th>score_std10</th>\n      <th>score_max10</th>\n      <th>score_min10</th>\n      <th>his_category_mean</th>\n      <th>his_category_median</th>\n      <th>his_category_std</th>\n      <th>his_category_max</th>\n      <th>his_category_min</th>\n      <th>score_last1</th>\n      <th>hardvalue_last1</th>\n      <th>score_last2</th>\n      <th>hardvalue_last2</th>\n      <th>score_last3</th>\n      <th>hardvalue_last3</th>\n      <th>is_midterm</th>\n      <th>is_final</th>\n      <th>term</th>\n      <th>le_course</th>\n      <th>le_exam_id</th>\n      <th>le_course_class</th>\n      <th>le_category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>230748</td>\n      <td>course1</td>\n      <td>E6OBmZgw</td>\n      <td>74.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>17.0</td>\n      <td>course_class1</td>\n      <td>18</td>\n      <td>275.0</td>\n      <td>45.0</td>\n      <td>S:11</td>\n      <td>C:2</td>\n      <td>0.269091</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>14.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>74.0</td>\n      <td>74.0</td>\n      <td>5.656854</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>73.75</td>\n      <td>73.5</td>\n      <td>4.349329</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>74.333333</td>\n      <td>73.5</td>\n      <td>4.926121</td>\n      <td>81.0</td>\n      <td>70.0</td>\n      <td>73.375</td>\n      <td>72.0</td>\n      <td>4.897157</td>\n      <td>81.0</td>\n      <td>67.0</td>\n      <td>73.888889</td>\n      <td>74.0</td>\n      <td>4.833333</td>\n      <td>81.0</td>\n      <td>67.0</td>\n      <td>73.818182</td>\n      <td>74.0</td>\n      <td>5.211875</td>\n      <td>81.0</td>\n      <td>67.0</td>\n      <td>73.692308</td>\n      <td>74.0</td>\n      <td>4.922476</td>\n      <td>81.0</td>\n      <td>67.0</td>\n      <td>73.400000</td>\n      <td>73.0</td>\n      <td>4.656792</td>\n      <td>81.0</td>\n      <td>67.0</td>\n      <td>73.117647</td>\n      <td>71.0</td>\n      <td>4.428351</td>\n      <td>81.0</td>\n      <td>67.0</td>\n      <td>76.50</td>\n      <td>77.5</td>\n      <td>4.654747</td>\n      <td>81.0</td>\n      <td>70.0</td>\n      <td>78.0</td>\n      <td>248.0</td>\n      <td>70.0</td>\n      <td>342.0</td>\n      <td>77.0</td>\n      <td>208.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92</td>\n      <td>0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186851</td>\n      <td>course1</td>\n      <td>E6OBmZgw</td>\n      <td>70.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>17.0</td>\n      <td>course_class1</td>\n      <td>18</td>\n      <td>275.0</td>\n      <td>45.0</td>\n      <td>S:11</td>\n      <td>C:2</td>\n      <td>0.254545</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>14.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>79.0</td>\n      <td>79.0</td>\n      <td>4.242641</td>\n      <td>82.0</td>\n      <td>76.0</td>\n      <td>76.00</td>\n      <td>75.0</td>\n      <td>4.320494</td>\n      <td>82.0</td>\n      <td>72.0</td>\n      <td>76.000000</td>\n      <td>75.5</td>\n      <td>3.405877</td>\n      <td>82.0</td>\n      <td>72.0</td>\n      <td>78.500</td>\n      <td>76.5</td>\n      <td>5.554921</td>\n      <td>88.0</td>\n      <td>72.0</td>\n      <td>80.111111</td>\n      <td>77.0</td>\n      <td>7.096556</td>\n      <td>93.0</td>\n      <td>72.0</td>\n      <td>82.090909</td>\n      <td>82.0</td>\n      <td>8.336121</td>\n      <td>98.0</td>\n      <td>72.0</td>\n      <td>81.307692</td>\n      <td>79.0</td>\n      <td>7.888648</td>\n      <td>98.0</td>\n      <td>72.0</td>\n      <td>80.400000</td>\n      <td>77.0</td>\n      <td>7.707140</td>\n      <td>98.0</td>\n      <td>72.0</td>\n      <td>79.294118</td>\n      <td>76.0</td>\n      <td>7.982518</td>\n      <td>98.0</td>\n      <td>67.0</td>\n      <td>74.75</td>\n      <td>75.0</td>\n      <td>2.217356</td>\n      <td>77.0</td>\n      <td>72.0</td>\n      <td>76.0</td>\n      <td>248.0</td>\n      <td>72.0</td>\n      <td>342.0</td>\n      <td>74.0</td>\n      <td>208.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92</td>\n      <td>0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>478370</td>\n      <td>course1</td>\n      <td>E6OBmZgw</td>\n      <td>78.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>17.0</td>\n      <td>course_class1</td>\n      <td>18</td>\n      <td>275.0</td>\n      <td>45.0</td>\n      <td>S:11</td>\n      <td>C:2</td>\n      <td>0.283636</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>14.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>80.0</td>\n      <td>80.0</td>\n      <td>1.414214</td>\n      <td>81.0</td>\n      <td>79.0</td>\n      <td>79.25</td>\n      <td>80.0</td>\n      <td>2.362908</td>\n      <td>81.0</td>\n      <td>76.0</td>\n      <td>79.666667</td>\n      <td>80.0</td>\n      <td>3.983298</td>\n      <td>86.0</td>\n      <td>75.0</td>\n      <td>78.125</td>\n      <td>77.5</td>\n      <td>4.486090</td>\n      <td>86.0</td>\n      <td>72.0</td>\n      <td>78.777778</td>\n      <td>79.0</td>\n      <td>4.630815</td>\n      <td>86.0</td>\n      <td>72.0</td>\n      <td>78.909091</td>\n      <td>79.0</td>\n      <td>4.826066</td>\n      <td>86.0</td>\n      <td>72.0</td>\n      <td>80.230769</td>\n      <td>81.0</td>\n      <td>5.464337</td>\n      <td>88.0</td>\n      <td>72.0</td>\n      <td>80.666667</td>\n      <td>81.0</td>\n      <td>5.354126</td>\n      <td>88.0</td>\n      <td>72.0</td>\n      <td>80.882353</td>\n      <td>81.0</td>\n      <td>5.194737</td>\n      <td>88.0</td>\n      <td>72.0</td>\n      <td>81.00</td>\n      <td>81.0</td>\n      <td>4.082483</td>\n      <td>86.0</td>\n      <td>76.0</td>\n      <td>81.0</td>\n      <td>248.0</td>\n      <td>76.0</td>\n      <td>342.0</td>\n      <td>81.0</td>\n      <td>208.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92</td>\n      <td>0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>692328</td>\n      <td>course1</td>\n      <td>E6OBmZgw</td>\n      <td>80.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>17.0</td>\n      <td>course_class1</td>\n      <td>18</td>\n      <td>275.0</td>\n      <td>45.0</td>\n      <td>S:11</td>\n      <td>C:2</td>\n      <td>0.290909</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>14.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>82.0</td>\n      <td>82.0</td>\n      <td>2.828427</td>\n      <td>84.0</td>\n      <td>80.0</td>\n      <td>80.25</td>\n      <td>81.0</td>\n      <td>3.862210</td>\n      <td>84.0</td>\n      <td>75.0</td>\n      <td>82.166667</td>\n      <td>82.5</td>\n      <td>4.622409</td>\n      <td>89.0</td>\n      <td>75.0</td>\n      <td>82.375</td>\n      <td>82.5</td>\n      <td>4.068608</td>\n      <td>89.0</td>\n      <td>75.0</td>\n      <td>83.444444</td>\n      <td>83.0</td>\n      <td>4.977728</td>\n      <td>92.0</td>\n      <td>75.0</td>\n      <td>84.090909</td>\n      <td>83.0</td>\n      <td>5.889899</td>\n      <td>95.0</td>\n      <td>75.0</td>\n      <td>83.923077</td>\n      <td>83.0</td>\n      <td>5.407734</td>\n      <td>95.0</td>\n      <td>75.0</td>\n      <td>83.733333</td>\n      <td>83.0</td>\n      <td>5.035115</td>\n      <td>95.0</td>\n      <td>75.0</td>\n      <td>83.235294</td>\n      <td>82.0</td>\n      <td>4.943802</td>\n      <td>95.0</td>\n      <td>75.0</td>\n      <td>81.50</td>\n      <td>81.0</td>\n      <td>5.802298</td>\n      <td>89.0</td>\n      <td>75.0</td>\n      <td>80.0</td>\n      <td>248.0</td>\n      <td>75.0</td>\n      <td>342.0</td>\n      <td>82.0</td>\n      <td>208.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92</td>\n      <td>0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>509128</td>\n      <td>course1</td>\n      <td>E6OBmZgw</td>\n      <td>72.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>17.0</td>\n      <td>course_class1</td>\n      <td>18</td>\n      <td>275.0</td>\n      <td>45.0</td>\n      <td>S:11</td>\n      <td>C:2</td>\n      <td>0.261818</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>14.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>76.5</td>\n      <td>76.5</td>\n      <td>6.363961</td>\n      <td>81.0</td>\n      <td>72.0</td>\n      <td>73.25</td>\n      <td>71.5</td>\n      <td>5.315073</td>\n      <td>81.0</td>\n      <td>69.0</td>\n      <td>74.333333</td>\n      <td>74.0</td>\n      <td>4.457204</td>\n      <td>81.0</td>\n      <td>69.0</td>\n      <td>75.625</td>\n      <td>76.5</td>\n      <td>4.470139</td>\n      <td>81.0</td>\n      <td>69.0</td>\n      <td>76.777778</td>\n      <td>77.0</td>\n      <td>5.426274</td>\n      <td>86.0</td>\n      <td>69.0</td>\n      <td>77.181818</td>\n      <td>77.0</td>\n      <td>6.096199</td>\n      <td>87.0</td>\n      <td>69.0</td>\n      <td>77.307692</td>\n      <td>77.0</td>\n      <td>5.588450</td>\n      <td>87.0</td>\n      <td>69.0</td>\n      <td>77.000000</td>\n      <td>77.0</td>\n      <td>5.250850</td>\n      <td>87.0</td>\n      <td>69.0</td>\n      <td>76.588235</td>\n      <td>76.0</td>\n      <td>5.075170</td>\n      <td>87.0</td>\n      <td>69.0</td>\n      <td>72.00</td>\n      <td>71.5</td>\n      <td>2.943920</td>\n      <td>76.0</td>\n      <td>69.0</td>\n      <td>72.0</td>\n      <td>248.0</td>\n      <td>69.0</td>\n      <td>342.0</td>\n      <td>71.0</td>\n      <td>208.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92</td>\n      <td>0</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "   student_id   course   exam_id  score  is_train  gender  exam_time   course_class  knowledge_cnt  hardvalue_sum  hardvalue_max section category  effotvalue  hardvalue_rank  category_rank  exam_time01  exam_time02  exam_time03  exam_time04  exam_time06  exam_time08  exam_time09  score_mean01  score_median01  score_std01  score_max01  score_min01  score_mean02  score_median02  score_std02  score_max02  score_min02  score_mean03  score_median03  score_std03  score_max03  score_min03  score_mean04  score_median04  score_std04  score_max04  score_min04  score_mean05  score_median05  score_std05  score_max05  score_min05  score_mean06  score_median06  score_std06  score_max06  score_min06  score_mean07  score_median07  score_std07  score_max07  score_min07  score_mean08  score_median08  score_std08  score_max08  score_min08  score_mean09  score_median09  score_std09  score_max09  score_min09  score_mean10  score_median10  score_std10  score_max10  score_min10  his_category_mean  \\\n0      230748  course1  E6OBmZgw   74.0         1       0       17.0  course_class1             18          275.0           45.0    S:11      C:2    0.269091               5            NaN         16.0         14.0         12.0         10.0          7.0          3.0          1.0           NaN             NaN          NaN          NaN          NaN          74.0            74.0     5.656854         78.0         70.0         73.75            73.5     4.349329         78.0         70.0     74.333333            73.5     4.926121         81.0         70.0        73.375            72.0     4.897157         81.0         67.0     73.888889            74.0     4.833333         81.0         67.0     73.818182            74.0     5.211875         81.0         67.0     73.692308            74.0     4.922476         81.0         67.0     73.400000            73.0     4.656792         81.0         67.0     73.117647            71.0     4.428351         81.0         67.0              76.50   \n1      186851  course1  E6OBmZgw   70.0         1       0       17.0  course_class1             18          275.0           45.0    S:11      C:2    0.254545               5            NaN         16.0         14.0         12.0         10.0          7.0          3.0          1.0           NaN             NaN          NaN          NaN          NaN          79.0            79.0     4.242641         82.0         76.0         76.00            75.0     4.320494         82.0         72.0     76.000000            75.5     3.405877         82.0         72.0        78.500            76.5     5.554921         88.0         72.0     80.111111            77.0     7.096556         93.0         72.0     82.090909            82.0     8.336121         98.0         72.0     81.307692            79.0     7.888648         98.0         72.0     80.400000            77.0     7.707140         98.0         72.0     79.294118            76.0     7.982518         98.0         67.0              74.75   \n2      478370  course1  E6OBmZgw   78.0         1       0       17.0  course_class1             18          275.0           45.0    S:11      C:2    0.283636               5            NaN         16.0         14.0         12.0         10.0          7.0          3.0          1.0           NaN             NaN          NaN          NaN          NaN          80.0            80.0     1.414214         81.0         79.0         79.25            80.0     2.362908         81.0         76.0     79.666667            80.0     3.983298         86.0         75.0        78.125            77.5     4.486090         86.0         72.0     78.777778            79.0     4.630815         86.0         72.0     78.909091            79.0     4.826066         86.0         72.0     80.230769            81.0     5.464337         88.0         72.0     80.666667            81.0     5.354126         88.0         72.0     80.882353            81.0     5.194737         88.0         72.0              81.00   \n3      692328  course1  E6OBmZgw   80.0         1       1       17.0  course_class1             18          275.0           45.0    S:11      C:2    0.290909               5            NaN         16.0         14.0         12.0         10.0          7.0          3.0          1.0           NaN             NaN          NaN          NaN          NaN          82.0            82.0     2.828427         84.0         80.0         80.25            81.0     3.862210         84.0         75.0     82.166667            82.5     4.622409         89.0         75.0        82.375            82.5     4.068608         89.0         75.0     83.444444            83.0     4.977728         92.0         75.0     84.090909            83.0     5.889899         95.0         75.0     83.923077            83.0     5.407734         95.0         75.0     83.733333            83.0     5.035115         95.0         75.0     83.235294            82.0     4.943802         95.0         75.0              81.50   \n4      509128  course1  E6OBmZgw   72.0         1       0       17.0  course_class1             18          275.0           45.0    S:11      C:2    0.261818               5            NaN         16.0         14.0         12.0         10.0          7.0          3.0          1.0           NaN             NaN          NaN          NaN          NaN          76.5            76.5     6.363961         81.0         72.0         73.25            71.5     5.315073         81.0         69.0     74.333333            74.0     4.457204         81.0         69.0        75.625            76.5     4.470139         81.0         69.0     76.777778            77.0     5.426274         86.0         69.0     77.181818            77.0     6.096199         87.0         69.0     77.307692            77.0     5.588450         87.0         69.0     77.000000            77.0     5.250850         87.0         69.0     76.588235            76.0     5.075170         87.0         69.0              72.00   \n\n   his_category_median  his_category_std  his_category_max  his_category_min  score_last1  hardvalue_last1  score_last2  hardvalue_last2  score_last3  hardvalue_last3  is_midterm  is_final  term  le_course  le_exam_id  le_course_class  le_category  \n0                 77.5          4.654747              81.0              70.0         78.0            248.0         70.0            342.0         77.0            208.0           1         0     1          0          92                0           11  \n1                 75.0          2.217356              77.0              72.0         76.0            248.0         72.0            342.0         74.0            208.0           1         0     1          0          92                0           11  \n2                 81.0          4.082483              86.0              76.0         81.0            248.0         76.0            342.0         81.0            208.0           1         0     1          0          92                0           11  \n3                 81.0          5.802298              89.0              75.0         80.0            248.0         75.0            342.0         82.0            208.0           1         0     1          0          92                0           11  \n4                 71.5          2.943920              76.0              69.0         72.0            248.0         69.0            342.0         71.0            208.0           1         0     1          0          92                0           11  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = pd.read_csv(open(feature_path+\"data_plus_score0825.csv\",encoding=\"utf8\"))\n",
    "###################### 增加期中 期末 学期\n",
    "is_midterm={\"course1\":[5,17,27,37,48,58,68,78],\n",
    "    \"course2\":[5,17,28,39,51,63,75,87],\n",
    "    \"course3\":[4,12,21,30,40,48,56,65],\n",
    "    \"course4\":[4,13,22,30,38,47,54,63],\n",
    "    \"course5\":[4,15,27,38,49,59,70,83],\n",
    "    \"course6\":[3,11,17,23,30,37,43,50],\n",
    "    \"course7\":[4,14,24,34,44,54,63,72],\n",
    "    \"course8\":[4,14,24,35,45,54,63,73]\n",
    "}\n",
    "is_final={\"course1\":[-1,11,22,31,43,53,63,72,84],\n",
    "    \"course2\":[-1,11,22,33,45,57,69,80,93],\n",
    "    \"course3\":[-1,8,16,25,35,44,52,60,69],\n",
    "    \"course4\":[-1,8,17,26,33,43,50,58,67],\n",
    "    \"course5\":[-1,9,21,33,43,54,64,76,89],\n",
    "    \"course6\":[-1,7,14,20,26,33,40,46,53],\n",
    "    \"course7\":[-1,8,19,29,39,49,58,67,77],\n",
    "    \"course8\":[-1,9,19,29,40,49,58,68,77]\n",
    "}\n",
    "data_all[\"is_midterm\"] = 0 #是否期中\n",
    "data_all[\"is_final\"] = 0 #是否期末\n",
    "data_all[\"term\"] = 0 #学期数\n",
    "for key in is_midterm.keys():\n",
    "    data_all.loc[(data_all[\"course\"]==key)&(data_all[\"exam_time\"].isin(is_midterm[key])),\"is_midterm\"]=1\n",
    "    data_all.loc[(data_all[\"course\"] == key) & (data_all[\"exam_time\"].isin(is_final[key])), \"is_final\"] = 1\n",
    "    term = data_all.loc[data_all[\"course\"]==key,\"exam_time\"]\n",
    "    data_all.loc[data_all[\"course\"] == key, \"term\"] = pd.cut(term,is_final[key],labels=False)\n",
    "############################\n",
    "print(data_all.shape)\n",
    "data_all = data_all.loc[data_all.score!=0] #去除包含0的值\n",
    "print(data_all.shape)\n",
    "# data_all2 = pd.read_csv(open(feature_path+\"gupengfeaturegupeng_course_feature.csv\",encoding=\"utf8\"))\n",
    "\n",
    "# 方案1：去除缺失较多的行\n",
    "# data_all = data_all.loc[np.isnan(data_all[\"category_rank\"])==0] #去除阶段性考试\n",
    "data_all = data_all.loc[np.isnan(data_all[\"his_category_mean\"])==0] #去除his_category空值\n",
    "data_all = data_all.loc[np.isnan(data_all[\"score_mean05\"])==0] #去除05空值\n",
    "data_all = data_all.loc[np.isnan(data_all[\"score_mean07\"])==0] #去除07空值\n",
    "data_all = data_all.loc[np.isnan(data_all[\"score_mean10\"])==0] #去除10空值\n",
    "print(data_all.shape)\n",
    "\n",
    "data_all = data_all.reset_index(drop=True)\n",
    "# data_all = data_all.merge(data_all2,on = ['student_id','course','exam_id','is_train'],how = 'left')\n",
    "data_all_temp = data_all.copy()\n",
    "le = LabelEncoder()\n",
    "data_all_temp[\"le_course\"] = le.fit_transform(data_all_temp[\"course\"])\n",
    "le = LabelEncoder()\n",
    "data_all_temp[\"le_exam_id\"] = le.fit_transform(data_all_temp[\"exam_id\"])\n",
    "le = LabelEncoder()\n",
    "data_all_temp[\"le_course_class\"] = le.fit_transform(data_all_temp[\"course_class\"])\n",
    "le = LabelEncoder()\n",
    "data_all_temp[\"le_category\"] = le.fit_transform(data_all_temp[\"category\"])\n",
    "\n",
    "y = \"score\"\n",
    "\n",
    "features = [\"gender\",\"exam_time\",\"knowledge_cnt\",\"category_rank\"]\\\n",
    "          +[\"hardvalue_sum\",\"hardvalue_max\",\"hardvalue_rank\"] \\\n",
    "          + [i for i in data_all_temp.columns if \"his_category_\" in i] \\\n",
    "          +[\"le_course\",\"le_course_class\",\"le_category\"] \\\n",
    "          + [i for i in data_all_temp.columns if \"05\" in i] \\\n",
    "          + [i for i in data_all_temp.columns if \"07\" in i] \\\n",
    "          + [i for i in data_all_temp.columns if \"_last\" in i] \\\n",
    "            + [i for i in data_all_temp.columns if \"10\" in i] \\\n",
    "            + [i for i in data_all_temp.columns if \"01\" in i] \\\n",
    "            + [i for i in data_all_temp.columns if \"03\" in i] \\\n",
    "            + [\"term\",\"is_midterm\",\"is_final\"]\\\n",
    "            # + [i for i in data_all_temp.columns if \"02\" in i] \\\n",
    "            # + [i for i in data_all_temp.columns if \"04\" in i] \\\n",
    "\n",
    "\"\"\"\n",
    "4.732\n",
    "02 4.729\n",
    "\"\"\"\n",
    "\n",
    "categorical_feats = [\"le_course\",\"le_course_class\",\"le_category\",\"gender\"]\n",
    "print(features)\n",
    "data_all_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "E087447A4A594DA182476D4EF0F2BA48",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n  warnings.warn('Using categorical_feature in Dataset.')\n/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n[500]\ttraining's rmse: 3.04772\tvalid_1's rmse: 3.11214\n[1000]\ttraining's rmse: 2.94572\tvalid_1's rmse: 3.03702\n[1500]\ttraining's rmse: 2.89006\tvalid_1's rmse: 3.00998\n[2000]\ttraining's rmse: 2.84595\tvalid_1's rmse: 2.99581\n[2500]\ttraining's rmse: 2.80925\tvalid_1's rmse: 2.98887\n[3000]\ttraining's rmse: 2.77623\tvalid_1's rmse: 2.98528\n[3500]\ttraining's rmse: 2.7456\tvalid_1's rmse: 2.98294\n[4000]\ttraining's rmse: 2.7175\tvalid_1's rmse: 2.98195\nEarly stopping, best iteration is:\n[3920]\ttraining's rmse: 2.72197\tvalid_1's rmse: 2.98181\nfold 1\nTraining until validation scores don't improve for 100 rounds.\n[500]\ttraining's rmse: 3.04909\tvalid_1's rmse: 3.10388\n[1000]\ttraining's rmse: 2.94525\tvalid_1's rmse: 3.02908\n[1500]\ttraining's rmse: 2.88749\tvalid_1's rmse: 3.00021\n[2000]\ttraining's rmse: 2.84468\tvalid_1's rmse: 2.98791\n[2500]\ttraining's rmse: 2.80941\tvalid_1's rmse: 2.98188\nEarly stopping, best iteration is:\n[2869]\ttraining's rmse: 2.78501\tvalid_1's rmse: 2.97974\nfold 2\nTraining until validation scores don't improve for 100 rounds.\n[500]\ttraining's rmse: 3.05048\tvalid_1's rmse: 3.08761\n[1000]\ttraining's rmse: 2.94519\tvalid_1's rmse: 3.01497\n[1500]\ttraining's rmse: 2.88985\tvalid_1's rmse: 2.99119\n[2000]\ttraining's rmse: 2.84725\tvalid_1's rmse: 2.9795\n[2500]\ttraining's rmse: 2.81093\tvalid_1's rmse: 2.97316\n[3000]\ttraining's rmse: 2.77907\tvalid_1's rmse: 2.96994\n[3500]\ttraining's rmse: 2.74872\tvalid_1's rmse: 2.96822\n[4000]\ttraining's rmse: 2.71896\tvalid_1's rmse: 2.96715\nEarly stopping, best iteration is:\n[4189]\ttraining's rmse: 2.70811\tvalid_1's rmse: 2.96676\nfold 3\nTraining until validation scores don't improve for 100 rounds.\n[500]\ttraining's rmse: 3.04571\tvalid_1's rmse: 3.09564\n[1000]\ttraining's rmse: 2.94772\tvalid_1's rmse: 3.02816\n[1500]\ttraining's rmse: 2.88924\tvalid_1's rmse: 2.99864\n[2000]\ttraining's rmse: 2.84703\tvalid_1's rmse: 2.98661\n[2500]\ttraining's rmse: 2.81091\tvalid_1's rmse: 2.97932\n[3000]\ttraining's rmse: 2.77771\tvalid_1's rmse: 2.97562\n[3500]\ttraining's rmse: 2.74764\tvalid_1's rmse: 2.97403\nEarly stopping, best iteration is:\n[3620]\ttraining's rmse: 2.74006\tvalid_1's rmse: 2.97375\nfold 4\nTraining until validation scores don't improve for 100 rounds.\n[500]\ttraining's rmse: 3.05255\tvalid_1's rmse: 3.08669\n[1000]\ttraining's rmse: 2.9485\tvalid_1's rmse: 3.01056\n[1500]\ttraining's rmse: 2.89189\tvalid_1's rmse: 2.98308\n[2000]\ttraining's rmse: 2.85015\tvalid_1's rmse: 2.97019\n[2500]\ttraining's rmse: 2.8146\tvalid_1's rmse: 2.96415\nEarly stopping, best iteration is:\n[2802]\ttraining's rmse: 2.7944\tvalid_1's rmse: 2.96211\n2.973\nCV score: 4.73200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n    </tr>\n    <tr>\n      <th>Feature</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>le_category</th>\n      <td>9286.2</td>\n    </tr>\n    <tr>\n      <th>hardvalue_sum</th>\n      <td>4594.6</td>\n    </tr>\n    <tr>\n      <th>hardvalue_last1</th>\n      <td>4462.6</td>\n    </tr>\n    <tr>\n      <th>score_std03</th>\n      <td>4314.4</td>\n    </tr>\n    <tr>\n      <th>score_std10</th>\n      <td>4000.2</td>\n    </tr>\n    <tr>\n      <th>score_std05</th>\n      <td>3746.2</td>\n    </tr>\n    <tr>\n      <th>score_std07</th>\n      <td>3552.2</td>\n    </tr>\n    <tr>\n      <th>score_mean03</th>\n      <td>3337.4</td>\n    </tr>\n    <tr>\n      <th>score_mean10</th>\n      <td>2909.0</td>\n    </tr>\n    <tr>\n      <th>his_category_mean</th>\n      <td>2882.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "                   importance\nFeature                      \nle_category            9286.2\nhardvalue_sum          4594.6\nhardvalue_last1        4462.6\nscore_std03            4314.4\nscore_std10            4000.2\nscore_std05            3746.2\nscore_std07            3552.2\nscore_mean03           3337.4\nscore_mean10           2909.0\nhis_category_mean      2882.2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log10\n",
    "# categorical_feats = []\n",
    "train = data_all_temp[data_all.is_train==1]\n",
    "test = data_all_temp[data_all.is_train==0]\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2333)\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "train_x = train[features]\n",
    "test_x = test[features]\n",
    "train_y = train[y]\n",
    "\n",
    "param = {'objective': 'regression',\n",
    "         'num_leaves': 2**5, #2**5\n",
    "         'min_data_in_leaf': 25,#\n",
    "         'max_depth': 5,  #\n",
    "         'learning_rate': 0.02, #0.02\n",
    "         'lambda_l1': 0.13,#0.13\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7,#0.85\n",
    "         'bagging_freq': 8,\n",
    "         \"bagging_fraction\": 0.9, #0.9\n",
    "         \"metric\": 'rmse',\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333,\n",
    "         \"num_threads\" : 50}\n",
    "# lgb\n",
    "model = \"lgb\"\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_x.values, train_y.values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_x.iloc[trn_idx],\n",
    "                           label=train_y.iloc[trn_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                           )\n",
    "    val_data = lgb.Dataset(train_x.iloc[val_idx],\n",
    "                           label=train_y.iloc[val_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                           )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=500,early_stopping_rounds=100)\n",
    "    #n*6矩阵\n",
    "    oof[val_idx] = clf.predict(train_x.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    predictions += clf.predict(test_x, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "feature_importance = feature_importance_df[[\"Feature\", \"importance\"]].groupby(\"Feature\").mean().sort_values(by=\"importance\",\n",
    "ascending=False)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(round(metrics.mean_squared_error(oof, train_y) ** 0.5,3))\n",
    "rmse = round(10*log10(metrics.mean_squared_error(oof, train_y) ** 0.5),3)\n",
    "print(\"CV score: {:<8.5f}\".format(rmse))\n",
    "\n",
    "#提交答案\n",
    "test[\"pred\"] = predictions\n",
    "\n",
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EDCD0AE185DE44F786CAF2E53B9EE0A5",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>course</th>\n      <th>exam_id</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>230748</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>86.373045</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186851</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>82.087835</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>478370</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>81.909700</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>692328</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>81.812192</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>509128</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>82.737889</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "   student_id   course   exam_id       pred\n0      230748  course1  PcVABZEp  86.373045\n1      186851  course1  PcVABZEp  82.087835\n2      478370  course1  PcVABZEp  81.909700\n3      692328  course1  PcVABZEp  81.812192\n4      509128  course1  PcVABZEp  82.737889"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub =pd.read_csv(open(data_path+\"submission_s2.csv\",encoding='utf8'))\n",
    "del sub[\"pred\"]\n",
    "sub = sub.merge(test[[\"student_id\", \"course\", \"exam_id\",\"pred\"]],how='left',on=[\"student_id\", \"course\", \"exam_id\"])\n",
    "sub.to_csv(out_path+\"result_old_{}.csv\".format(rmse),index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "419DDA91ED734E8D8E832C3EBACD01B3",
    "mdEditEnable": false
   },
   "source": [
    "# 模型2：期末考试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4CDFD4A698C743AE81BBCAB87E00BB09",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_knowledge = pd.read_csv(open(data_path + 'all_knowledge.csv',encoding='utf8'))#2236\n",
    "course1_exams = pd.read_csv(open(data_path + 'course1_exams.csv',encoding='utf8'))#85,369 考点依次向后，最后为综合性考试\n",
    "course2_exams = pd.read_csv(open(data_path + 'course2_exams.csv',encoding='utf8')) #94,368\n",
    "course3_exams = pd.read_csv(open(data_path + 'course3_exams.csv',encoding='utf8'))#70，263\n",
    "course4_exams = pd.read_csv(open(data_path + 'course4_exams.csv',encoding='utf8'))#68,220\n",
    "course5_exams = pd.read_csv(open(data_path + 'course5_exams.csv',encoding='utf8'))#90,336\n",
    "course6_exams = pd.read_csv(open(data_path + 'course6_exams.csv',encoding='utf8'))#54,147\n",
    "course7_exams = pd.read_csv(open(data_path + 'course7_exams.csv',encoding='utf8'))#78,317\n",
    "course8_exams = pd.read_csv(open(data_path + 'course8_exams.csv',encoding='utf8'))#78,224\n",
    "train = pd.read_csv(open(data_path + 'exam_score.csv',encoding='utf8')) #共8门课 65500,4/304500,4\n",
    "student = pd.read_csv(open(data_path + 'student.csv',encoding='utf8'))#500,2\n",
    "course = pd.read_csv(open(data_path + 'course.csv',encoding='utf8'))#8,2\n",
    "test = pd.read_csv(open(data_path + 'submission_s2.csv',encoding='utf8'))#8000,5/4000,4 最后一次考试为最后半年的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9D04BA83CF2B413C839C507A7FE2B0E5",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "#考试特征聚合\n",
    "exams = pd.DataFrame({\"exam_id\":[],\"level_1\":[],0:[],\"course\":[]})\n",
    "for i in range(1,9):\n",
    "    s=0\n",
    "    exec(\"\"\"s = course{}_exams.set_index(\"exam_id\").stack().to_frame().reset_index()\"\"\".format(i))\n",
    "    exam_list = s[\"exam_id\"].drop_duplicates().values\n",
    "    s_temp = pd.DataFrame({\"exam_id\":exam_list,\"exam_time\":range(len(exam_list))})\n",
    "    s = s.merge(s_temp,how='left',on=\"exam_id\")\n",
    "    s[\"course\"] = \"course{}\".format(i)\n",
    "    exams = exams.append(s)\n",
    "\n",
    "exams = exams.rename(columns={0:\"score\"})\n",
    "\n",
    "# 合并所有和考试相关的信息\n",
    "exams = exams.merge(all_knowledge,how='left',left_on=[\"course\",\"level_1\"],right_on=[\"course\",\"knowledge_point\"])\n",
    "exams = exams.merge(course,how='left',on='course')\n",
    "exams[\"hardvalue\"] = 0.01*exams[\"score\"]*exams[\"complexity\"] #难度值\n",
    "exams[\"rank\"] = exams.groupby(\"exam_id\")[\"score\"].rank(ascending=False,method='first')\n",
    "exams[\"score\"] = exams[\"score\"].replace(0,np.nan)\n",
    "\n",
    "#将所有考试信息归到一维\n",
    "agg = {\n",
    "    \"score\":[\"count\"],#考了几个知识点\n",
    "    \"hardvalue\":[\"sum\",\"max\"], #难度值、难度最高的知识点有多高\n",
    "}\n",
    "exams_group = exams.groupby([\"exam_id\",\"exam_time\",\"course\",\"course_class\"],as_index=False).agg(agg) #617,2\n",
    "exams_group.columns=[\"exam_id\",\"exam_time\",\"course\",\"course_class\",\"knowledge_cnt\",\"hardvalue_sum\",\"hardvalue_max\"]\n",
    "exams_group = exams_group.merge(exams.loc[exams[\"rank\"]==1][[\"exam_id\",\"section\",\"category\"]],how=\"left\",on=[\"exam_id\"])#本次考试的知识点所属领域\n",
    "exams_group = exams_group.sort_values([\"course\",\"exam_time\"])\n",
    "# exam_all = exam_all.merge(exams_group,how='left',on=[\"exam_id\",\"course\"])\n",
    "is_midterm={\"course1\":[5,17,27,37,48,58,68,78],\n",
    "    \"course2\":[5,17,28,39,51,63,75,87],\n",
    "    \"course3\":[4,12,21,30,40,48,56,65],\n",
    "    \"course4\":[4,13,22,30,38,47,54,63],\n",
    "    \"course5\":[4,15,27,38,49,59,70,83],\n",
    "    \"course6\":[3,11,17,23,30,37,43,50],\n",
    "    \"course7\":[4,14,24,34,44,54,63,72],\n",
    "    \"course8\":[4,14,24,35,45,54,63,73]\n",
    "}\n",
    "is_final={\"course1\":[-1,11,22,31,43,53,63,72,84],\n",
    "    \"course2\":[-1,11,22,33,45,57,69,80,93],\n",
    "    \"course3\":[-1,8,16,25,35,44,52,60,69],\n",
    "    \"course4\":[-1,8,17,26,33,43,50,58,67],\n",
    "    \"course5\":[-1,9,21,33,43,54,64,76,89],\n",
    "    \"course6\":[-1,7,14,20,26,33,40,46,53],\n",
    "    \"course7\":[-1,8,19,29,39,49,58,67,77],\n",
    "    \"course8\":[-1,9,19,29,40,49,58,68,77]\n",
    "}\n",
    "exams_group[\"is_midterm\"] = 0 #是否期中\n",
    "exams_group[\"is_final\"] = 0 #是否期末\n",
    "exams_group[\"term\"] = 0 #学期数\n",
    "for key in is_midterm.keys():\n",
    "    exams_group.loc[(exams_group[\"course\"]==key)&(exams_group[\"exam_time\"].isin(is_midterm[key])),\"is_midterm\"]=1\n",
    "    exams_group.loc[(exams_group[\"course\"] == key) & (exams_group[\"exam_time\"].isin(is_final[key])), \"is_final\"] = 1\n",
    "    term = exams_group.loc[exams_group[\"course\"]==key,\"exam_time\"]\n",
    "    exams_group.loc[exams_group[\"course\"] == key, \"term\"] = pd.cut(term,is_final[key],labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "570945EAD7B1409E8A0975C426BE5AC1",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n"
     ]
    }
   ],
   "source": [
    "#学生维度\n",
    "train[\"is_train\"]=1\n",
    "test[\"is_train\"]=0\n",
    "test.rename(columns = {'pred':'score'},inplace=True)\n",
    "data_all = train.append(test)\n",
    "data_all = data_all.merge(student,how='left',on='student_id')\n",
    "data_all = data_all.merge(exams_group,how='left',on=[\"exam_id\",\"course\"])\n",
    "data_all[\"effotvalue\"] = data_all[\"score\"]/data_all[\"hardvalue_sum\"]\n",
    "bin_labels = [0,1,2,3,4,5,6,7]\n",
    "data_all[\"hardvalue_rank\"]=pd.cut(data_all[\"hardvalue_sum\"], 8, right=True, labels=bin_labels, retbins=False, precision=3, include_lowest=False)\n",
    "#当前章节第几次考试,测试集中3/16次考试更换了知识点,category_rank为nan则说明为阶段性考试\n",
    "data_tmp = data_all.sort_values(by=[\"student_id\",\"course\",\"section\",\"knowledge_cnt\"])\n",
    "data_tmp = data_tmp.drop_duplicates([\"student_id\",\"course\",\"section\"])\n",
    "data_tmp[\"category_rank\"] = data_tmp.groupby([\"student_id\",\"course\",\"category\"])[\"exam_time\"].rank(method=\"first\")\n",
    "data_all = data_all.merge(data_tmp[[\"student_id\",\"course\",\"exam_time\",\"category_rank\"]],how='left',on=[\"student_id\",\"course\",\"exam_time\"])\n",
    "\n",
    "#每学期每门考试的统计\n",
    "data_course_group = data_all.loc[(data_all.is_final==0)&(data_all.score!=0)]\n",
    "agg = {\n",
    "    \"score\":[\"mean\",\"median\",\"std\",\"max\",\"min\",skew,kurtosis],\n",
    "    \"effotvalue\":[\"mean\",\"median\",\"std\",\"max\",\"min\",skew,kurtosis],\n",
    "}\n",
    "data_course_group = data_course_group.groupby([\"term\",\"course\"],as_index=False).agg(agg)\n",
    "data_course_group.columns = [\"term\",\"course\"]+[\"course_group_\"+i[0]+\"_\"+i[1] for i in data_course_group.columns[2:]]\n",
    "\n",
    "#对所有考试展开\n",
    "every_exam = data_all.loc[(data_all.is_final==0)&(data_all.is_midterm==0)]\n",
    "every_exam[\"exam_rank\"] = every_exam.groupby([\"term\",\"course\",\"student_id\"])[\"exam_time\"].rank(method='first')\n",
    "\n",
    "#每个章节的分数\n",
    "exams_final = exams.loc[exams.exam_id.isin(set(data_all[data_all.is_final==1].exam_id))]\n",
    "exams_final = exams_final.dropna(axis=0,how='any').rename(columns={\"exam_time\":\"exam_time_final\"})\n",
    "exams_final_tmp = exams_final.groupby([\"course\",\"section\"],as_index=False)[\"score\"].sum()\n",
    "exams_final_tmp = exams_final_tmp.rename(columns={\"score\":\"section_score\"})\n",
    "# exams_final_tmp[:20]\n",
    "every_exam = every_exam.merge(exams_final_tmp,how='left',on=[\"course\",\"section\"])\n",
    "every_exam[every_exam.student_id==230748]\n",
    "#data_all为全部数据\n",
    "for i in range(1,12):\n",
    "    print(i)\n",
    "    every_exam_tmp = every_exam.loc[every_exam.exam_rank==i][[\"term\",\"course\",\"student_id\",\"hardvalue_sum\",\"score\",\"section_score\"]]\n",
    "    every_exam_tmp[\"score\"] = every_exam_tmp[\"score\"].replace(0,np.nan)\n",
    "    every_exam_tmp.columns = [\"term\",\"course\",\"student_id\",\"last_hard{}\".format(i),\"last_exam{}\".format(i),\"section_score{}\".format(i)]\n",
    "    data_all = data_all.merge(every_exam_tmp,how='left',on=[\"term\",\"course\",\"student_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "20E71E672BB04DFC821A6E6345A959FE",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score==0: 601\ndata_all shape: (308500, 54)\ndata_all shape: (307955, 54)\n期中考试为0的数量 (0, 5)\n"
     ]
    }
   ],
   "source": [
    "#提取所有期末考试\n",
    "\n",
    "#对0分学生处理\n",
    "print(\"score==0:\",data_all.loc[data_all.score==0].shape[0])\n",
    "data_all[\"is_zero\"] = data_all.score.apply(lambda x: 1 if x ==0 else 0)\n",
    "data_all_zero = data_all.loc[data_all.is_final==0] #去除期末考试\n",
    "#计算一个学生所有0分情况\n",
    "data_all_zero = data_all_zero.groupby(\"student_id\",as_index=False)[\"is_zero\"].sum()\n",
    "data_all_zero = data_all_zero.rename(columns={\"is_zero\":\"his_zero_cnt\"})\n",
    "data_all = data_all.merge(data_all_zero,how='left',on=\"student_id\")\n",
    "\n",
    "print(\"data_all shape:\",data_all.shape)\n",
    "#每次期末考试大概有8个0分学生\n",
    "data_all = data_all.loc[(data_all.score!=0)|(data_all.is_final==1)]#选择所有期末考试及非期末中非0考试\n",
    "print(\"data_all shape:\",data_all.shape)\n",
    "data_final = data_all.loc[data_all.is_final==1]\n",
    "\n",
    "######统计特征1：对该学期所有考试进行统计（包括期中）###################################################################\n",
    "data_group = data_all.loc[data_all.is_final==0]\n",
    "from scipy.stats import skew,kurtosis\n",
    "\n",
    "#针对一个学生一门课程一学期考试做统计\n",
    "agg = {\n",
    "    \"score\":[\"mean\",\"median\",\"std\",\"max\",\"min\",skew,kurtosis],\n",
    "    \"effotvalue\":[\"mean\",\"median\",\"std\",\"max\",\"min\",skew,kurtosis],\n",
    "    \"section\":[\"count\"]\n",
    "}\n",
    "data_group = data_group.groupby([\"student_id\",\"course\",\"term\"],as_index=False).agg(agg)\n",
    "data_group.columns = [\"student_id\",\"course\",\"term\"]+[i[0]+\"_\"+i[1] for i in data_group.columns[3:]]\n",
    "data_final = data_final.merge(data_group,how='left',on=[\"student_id\",\"course\",\"term\"])\n",
    "\n",
    "#上一次期中考试及难度\n",
    "data_midterm = data_all.loc[data_all.is_midterm==1][[\"student_id\",\"course\",\"term\",\"score\",\"hardvalue_sum\"]]\n",
    "data_midterm = data_midterm.rename(columns={\"score\":\"last_exam_midterm\",\"hardvalue_sum\":\"last_hard_midterm\"})\n",
    "print(\"期中考试为0的数量\",data_midterm[data_midterm.last_exam_midterm==0].shape)\n",
    "data_final = data_final.merge(data_midterm,how='left',on=[\"student_id\",\"course\",\"term\"])\n",
    "\n",
    "######统计特征2：针对期末的每个知识点找到对应的单科考试成绩并加权#############################################\n",
    "#针对考试的知识点做统计 筛选非期中期末的考试\n",
    "data_group2 = data_all.loc[(data_all.is_final==0)&(data_all.is_midterm==0)][[\"student_id\",\"course\",\"term\",\"score\",\"hardvalue_sum\",\"section\",\"exam_time\"]]\n",
    "data_group2 = data_group2.sort_values([\"student_id\",\"course\",\"term\",\"exam_time\"])\n",
    "data_group2 = data_group2.rename(columns={\"score\":\"his_score\",\"hardvalue_sum\":\"his_hard\"})\n",
    "#提取期末考试的知识点 score为当前知识点score\n",
    "exams_final = exams.loc[exams.exam_id.isin(set(data_final.exam_id))]\n",
    "exams_final = exams_final.dropna(axis=0,how='any').rename(columns={\"exam_time\":\"exam_time_final\"})\n",
    "\n",
    "exams_final_tmp = exams_final.groupby([\"exam_id\",\"section\"],as_index=False)[\"score\"].sum()\n",
    "exams_final_tmp.columns = [\"exam_id\",\"section\",\"score_sum\"]\n",
    "exams_final = exams_final.merge(exams_final_tmp,how='left',on=[\"exam_id\",\"section\"])\n",
    "exams_final[\"score_hard\"] = (exams_final[\"score\"]/exams_final[\"score_sum\"])*exams_final[\"complexity\"]\n",
    "#当前章节分数及难度\n",
    "exams_final_group = exams_final.groupby([\"exam_id\",\"course\",\"exam_time_final\",\"section\"],as_index=False).agg({\"score_sum\":\"mean\",\"score_hard\":\"sum\"})\n",
    "exams_final_group = exams_final_group.rename(columns={\"score_sum\":\"score\"})\n",
    "\n",
    "exams_final = exams_final_group.merge(data_group2,how=\"left\",on=[\"course\",\"section\"])\n",
    "exams_final = exams_final.sort_values([\"student_id\",\"course\",\"term\",\"exam_time\"])\n",
    "\n",
    "#有学生章节考试为0分，故应考虑该情况\n",
    "exams_final_tmp2 = exams_final.groupby([\"student_id\",\"exam_id\"],as_index=False)[\"score\"].sum()\n",
    "exams_final_tmp2 = exams_final_tmp2.rename(columns={\"score\":\"score_sum\"})\n",
    "exams_final = exams_final.merge(exams_final_tmp2,how = 'left',on=[\"student_id\",\"exam_id\"])\n",
    "\n",
    "#score为期末考试每个章节分数，his_score为该学生历史章节考试成绩，his_hard为历史章节考试难度，score_hard为期末考试各章节难度\n",
    "# mean 6.76/1 6.67/2 6.63 7.34/3 6.60/4 6.58/5 6.57###\n",
    "# 3 4.305/4 4.253/5 4.227/6 4.226\n",
    "exams_final[\"pred_score\"] = (exams_final[\"score\"]/exams_final[\"score_sum\"])*(exams_final[\"his_score\"]+(exams_final[\"his_hard\"]-exams_final[\"score_hard\"])*4)\n",
    "exams_final_group2 = exams_final.groupby([\"exam_id\",\"course\",\"student_id\",\"term\"],as_index=False)[\"pred_score\"].sum()\n",
    "\n",
    "#合并\n",
    "data_final = data_final.merge(data_course_group,how='left',on=[\"term\",\"course\"])\n",
    "data_final = data_final.merge(exams_final_group2,how='left',on=[\"exam_id\",\"student_id\",\"course\",\"term\"])\n",
    "data_final = data_final.sort_values([\"student_id\",\"course\",\"term\"])\n",
    "#上一次期末考试及难度\n",
    "data_final[\"last_exam_final\"] = data_final.groupby([\"course\",\"student_id\"])[\"score\"].shift(1)\n",
    "data_final[\"last_hard_final\"] = data_final.groupby([\"course\",\"student_id\"])[\"hardvalue_sum\"].shift(1)\n",
    "data_final[\"last_exam_final2\"] = data_final.groupby([\"course\",\"student_id\"])[\"score\"].shift(2)\n",
    "data_final[\"last_hard_final2\"] = data_final.groupby([\"course\",\"student_id\"])[\"hardvalue_sum\"].shift(2)\n",
    "data_final[\"last_exam_final3\"] = data_final.groupby([\"course\",\"student_id\"])[\"score\"].shift(3)\n",
    "data_final[\"last_hard_final3\"] = data_final.groupby([\"course\",\"student_id\"])[\"hardvalue_sum\"].shift(3)\n",
    "data_final[\"last_exam_final4\"] = data_final.groupby([\"course\",\"student_id\"])[\"score\"].shift(4)\n",
    "data_final[\"last_hard_final4\"] = data_final.groupby([\"course\",\"student_id\"])[\"hardvalue_sum\"].shift(4)\n",
    "\n",
    "# 比例特征\n",
    "#章节考试之间的比例\n",
    "data_final[\"ratio_last_exam12\"] = data_final[\"last_exam1\"]/data_final[\"last_exam2\"]\n",
    "data_final[\"ratio_last_exam23\"] = data_final[\"last_exam2\"]/data_final[\"last_exam3\"]\n",
    "data_final[\"ratio_last_exam34\"] = data_final[\"last_exam3\"]/data_final[\"last_exam4\"]\n",
    "data_final[\"ratio_last_exam45\"] = data_final[\"last_exam4\"]/data_final[\"last_exam5\"]\n",
    "data_final[\"ratio_last_exam56\"] = data_final[\"last_exam5\"]/data_final[\"last_exam6\"]\n",
    "data_final[\"ratio_last_exam67\"] = data_final[\"last_exam6\"]/data_final[\"last_exam7\"]\n",
    "data_final[\"ratio_last_exam78\"] = data_final[\"last_exam7\"]/data_final[\"last_exam8\"]\n",
    "data_final[\"ratio_last_exam89\"] = data_final[\"last_exam8\"]/data_final[\"last_exam9\"]\n",
    "data_final[\"ratio_last_exam910\"] = data_final[\"last_exam9\"]/data_final[\"last_exam10\"]\n",
    "data_final[\"ratio_last_exam1011\"] = data_final[\"last_exam10\"]/data_final[\"last_exam11\"]\n",
    "\n",
    "data_final = data_final.sort_values([\"student_id\",\"term\",\"course\",\"exam_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "B13A5073C7164E148C2E2BCB5E8CBB83",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def embedding(series, size=8, ids=None, sp_weights=None, combiner=None):\n",
    "    \"\"\"\n",
    "    :param series: 要进行embedding的列,每行数据格式为[\"dog\",\"cat\",\"pig\"]或者\"dog cat pig\"\n",
    "    :param ids：所有word的排序[\"cat\",\"dog\",\"pig\"]\n",
    "    :param size: w2v的维度\n",
    "    :param sp_weights: 各类别的权重，是否加权，必须和ids具有相同的维度\n",
    "    :param combiner: 默认‘mean’，还可以选择 \"sqrtn\" \"sum\"\n",
    "    :return:word_vec w2v结果\n",
    "    :return:result_embedding[0] embedding结果\n",
    "    \"\"\"\n",
    "    type_s = type(series[0]).__name__\n",
    "    if type_s == 'list':\n",
    "        series_list = series.copy()\n",
    "        series_str = series.apply(lambda x: \" \".join(x))\n",
    "    elif type_s == 'str':\n",
    "        series_list = series.apply(lambda x: x.split(\" \"))\n",
    "        series_str = series.copy()\n",
    "    if ids == None:\n",
    "        ids = sorted(list(set(series_list.sum())))\n",
    "\n",
    "    word_list = []\n",
    "    for word in series_list:\n",
    "        word_list.append(word)\n",
    "    #参数根据实际情况修改\n",
    "    model = Word2Vec(word_list, size=size, window=3,\n",
    "                     min_count=1, workers=1,\n",
    "                     iter=20, seed=2019)\n",
    "    print(\"行为种类\", len(ids))\n",
    "\n",
    "    # 构造vec ids对应的vec，维度为 ids个数*n\n",
    "    word_vec = []\n",
    "    for id in ids:\n",
    "        word_vec.append(list(model[id]))\n",
    "    word_vec = np.array(word_vec).astype(np.float32)\n",
    "    print(\"w2v维度\", len(word_vec), len(word_vec[0]))\n",
    "    params = tf.Variable(word_vec)\n",
    "\n",
    "    # word count编码 若不加a则算法无法识别'0'~'9'\n",
    "    cv = CountVectorizer(min_df=1, max_df=999999)\n",
    "    alert_cv = cv.fit_transform(series_str)  # 元素位置 及值\n",
    "    name = cv.vocabulary_\n",
    "    name2 = sorted(name.items(), key=lambda x: x[1], reverse=False)\n",
    "    name_id = [kk[0] for kk in name2]\n",
    "\n",
    "    print(\"w2v和cv顺序是否一致\", ids == name_id)\n",
    "\n",
    "    #获取word count矩阵的行列位置，及对应的值\n",
    "    cv_row =list(alert_cv.tocoo().row.reshape(-1)) #cv的行\n",
    "    cv_col = list(alert_cv.tocoo().col.reshape(-1)) #cv的列\n",
    "    col_cnt = alert_cv.data.tolist()#col出现的次数\n",
    "    cv_df = pd.DataFrame({\"cv_row\":cv_row,\"cv_col\":cv_col,\"col_cnt\":col_cnt})\n",
    "\n",
    "    # 按照出现的次数展开\n",
    "    cv_row_new = []\n",
    "    cv_col_new = []\n",
    "    for ind in range(cv_df.shape[0]):\n",
    "        cv_row_new.extend([cv_df[\"cv_row\"][ind]] * cv_df[\"col_cnt\"][ind])\n",
    "        cv_col_new.extend([cv_df[\"cv_col\"][ind]] * cv_df[\"col_cnt\"][ind])\n",
    "    cv_df_new = pd.DataFrame({\"cv_row\": cv_row_new, \"cv_col\": cv_col_new})\n",
    "    cv_df_new[\"rank\"] = cv_df_new.groupby(\"cv_row\")[\"cv_col\"].rank(ascending=True, method=\"first\")\n",
    "    cv_df_new[\"rank\"] = (cv_df_new[\"rank\"] - 1).astype(int)\n",
    "\n",
    "    # 组合indices和values\n",
    "    indices = []\n",
    "    values = []\n",
    "    for ind in range(cv_df_new.shape[0]):\n",
    "        indices.append([cv_df_new[\"cv_row\"][ind], cv_df_new[\"rank\"][ind]])\n",
    "        values.append(cv_df_new[\"cv_col\"][ind])\n",
    "\n",
    "    # 构造embedding输入\n",
    "    tags = tf.SparseTensor(indices=indices, values=values,\n",
    "                           dense_shape=(cv_df_new[\"cv_row\"].max() + 1, cv_df_new[\"rank\"].max() + 1))\n",
    "    # a = tf.SparseTensor(indices=[[0, 0], [1, 2], [1, 3]], values=[1, 2, 3], dense_shape=[2, 4])\n",
    "    embedding_tags = tf.nn.embedding_lookup_sparse(params, sp_ids=tags, sp_weights=sp_weights, combiner=combiner)\n",
    "\n",
    "    with tf.Session() as s:\n",
    "        s.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        result_embedding = s.run([embedding_tags])\n",
    "    print(\"embedding完成,维度：{}\".format(result_embedding[0].shape))\n",
    "    return word_vec,result_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7FEC787DDAED45DE86FE8A6F995CCC56",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行为种类 51\nw2v维度 51 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:37: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v和cv顺序是否一致 True\nWARNING:tensorflow:The default value of combiner will change from \"mean\" to \"sqrtn\" after 2016/11/01.\nembedding完成,维度：(32000, 2)\n"
     ]
    }
   ],
   "source": [
    "def emb_trans(df):\n",
    "    tmp = []\n",
    "    for i in range(df[\"section_count\"]-1):\n",
    "        tt=df['last_exam{}'.format(i+1)]\n",
    "        try:\n",
    "            tt = 'a'+str(int(tt))\n",
    "        except:\n",
    "            tt='a'+str(tt)\n",
    "        tmp.append(tt)   \n",
    "    return tmp\n",
    "data_final[\"emb_exam_tmp\"] = data_final.apply(emb_trans,axis=1)\n",
    "\n",
    "exam_emb = embedding(data_final[\"emb_exam_tmp\"],size=2)[1]\n",
    "exam_emb = pd.DataFrame(exam_emb,columns=[\"emb_exam0\",\"emb_exam1\",\n",
    "                                            # \"emb_exam2\",\"emb_exam3\"\n",
    "                                            ])\n",
    "data_final = pd.concat([data_final,exam_emb],axis=1)\n",
    "del data_final[\"emb_exam_tmp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "49001FFC673448CA87A86FCBE6A257DB",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'exam_time', 'knowledge_cnt', 'hardvalue_sum', 'hardvalue_max', 'hardvalue_rank', 'score_mean', 'score_median', 'score_std', 'score_max', 'score_min', 'score_skew', 'score_kurtosis', 'le_course', 'le_course_class', 'effotvalue_mean', 'effotvalue_median', 'effotvalue_std', 'effotvalue_max', 'effotvalue_min', 'effotvalue_skew', 'effotvalue_kurtosis', 'last_hard1', 'last_exam1', 'last_hard2', 'last_exam2', 'last_hard3', 'last_exam3', 'last_hard4', 'last_exam4', 'last_hard5', 'last_exam5', 'last_hard6', 'last_exam6', 'last_hard7', 'last_exam7', 'last_hard8', 'last_exam8', 'last_hard9', 'last_exam9', 'last_hard10', 'last_exam10', 'last_hard11', 'last_exam11', 'last_exam_midterm', 'last_hard_midterm', 'last_exam_final', 'last_hard_final', 'last_exam_final2', 'last_hard_final2', 'last_exam_final3', 'last_hard_final3', 'last_exam_final4', 'last_hard_final4', 'section_count', 'pred_score', 'his_zero_cnt', 'section_score1', 'section_score2', 'section_score3', 'section_score4', 'section_score5', 'section_score6', 'section_score7', 'section_score8', 'section_score9', 'section_score10', 'section_score11', 'course_group_score_mean', 'course_group_score_median', 'course_group_score_std', 'course_group_score_max', 'course_group_score_min', 'course_group_score_skew', 'course_group_score_kurtosis', 'course_group_effotvalue_mean', 'course_group_effotvalue_median', 'course_group_effotvalue_std', 'course_group_effotvalue_max', 'course_group_effotvalue_min', 'course_group_effotvalue_skew', 'course_group_effotvalue_kurtosis', 'ratio_last_exam12', 'ratio_last_exam23', 'ratio_last_exam34', 'ratio_last_exam45', 'ratio_last_exam56', 'ratio_last_exam67', 'ratio_last_exam78', 'ratio_last_exam89', 'ratio_last_exam910', 'ratio_last_exam1011']\n92\ntrain shape: (27944, 109)\ntest shape: (4000, 109)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>exam_time</th>\n      <th>knowledge_cnt</th>\n      <th>hardvalue_sum</th>\n      <th>hardvalue_max</th>\n      <th>hardvalue_rank</th>\n      <th>score_mean</th>\n      <th>score_median</th>\n      <th>score_std</th>\n      <th>score_max</th>\n      <th>score_min</th>\n      <th>score_skew</th>\n      <th>score_kurtosis</th>\n      <th>le_course</th>\n      <th>le_course_class</th>\n      <th>effotvalue_mean</th>\n      <th>effotvalue_median</th>\n      <th>effotvalue_std</th>\n      <th>effotvalue_max</th>\n      <th>effotvalue_min</th>\n      <th>effotvalue_skew</th>\n      <th>effotvalue_kurtosis</th>\n      <th>last_hard1</th>\n      <th>last_exam1</th>\n      <th>last_hard2</th>\n      <th>last_exam2</th>\n      <th>last_hard3</th>\n      <th>last_exam3</th>\n      <th>last_hard4</th>\n      <th>last_exam4</th>\n      <th>last_hard5</th>\n      <th>last_exam5</th>\n      <th>last_hard6</th>\n      <th>last_exam6</th>\n      <th>last_hard7</th>\n      <th>last_exam7</th>\n      <th>last_hard8</th>\n      <th>last_exam8</th>\n      <th>last_hard9</th>\n      <th>last_exam9</th>\n      <th>last_hard10</th>\n      <th>last_exam10</th>\n      <th>last_hard11</th>\n      <th>last_exam11</th>\n      <th>last_exam_midterm</th>\n      <th>last_hard_midterm</th>\n      <th>last_exam_final</th>\n      <th>last_hard_final</th>\n      <th>last_exam_final2</th>\n      <th>last_hard_final2</th>\n      <th>last_exam_final3</th>\n      <th>last_hard_final3</th>\n      <th>last_exam_final4</th>\n      <th>last_hard_final4</th>\n      <th>section_count</th>\n      <th>pred_score</th>\n      <th>his_zero_cnt</th>\n      <th>section_score1</th>\n      <th>section_score2</th>\n      <th>section_score3</th>\n      <th>section_score4</th>\n      <th>section_score5</th>\n      <th>section_score6</th>\n      <th>section_score7</th>\n      <th>section_score8</th>\n      <th>section_score9</th>\n      <th>section_score10</th>\n      <th>section_score11</th>\n      <th>course_group_score_mean</th>\n      <th>course_group_score_median</th>\n      <th>course_group_score_std</th>\n      <th>course_group_score_max</th>\n      <th>course_group_score_min</th>\n      <th>course_group_score_skew</th>\n      <th>course_group_score_kurtosis</th>\n      <th>course_group_effotvalue_mean</th>\n      <th>course_group_effotvalue_median</th>\n      <th>course_group_effotvalue_std</th>\n      <th>course_group_effotvalue_max</th>\n      <th>course_group_effotvalue_min</th>\n      <th>course_group_effotvalue_skew</th>\n      <th>course_group_effotvalue_kurtosis</th>\n      <th>ratio_last_exam12</th>\n      <th>ratio_last_exam23</th>\n      <th>ratio_last_exam34</th>\n      <th>ratio_last_exam45</th>\n      <th>ratio_last_exam56</th>\n      <th>ratio_last_exam67</th>\n      <th>ratio_last_exam78</th>\n      <th>ratio_last_exam89</th>\n      <th>ratio_last_exam910</th>\n      <th>ratio_last_exam1011</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>11.0</td>\n      <td>18</td>\n      <td>2.73</td>\n      <td>0.33</td>\n      <td>5</td>\n      <td>72.454545</td>\n      <td>71.0</td>\n      <td>4.227615</td>\n      <td>80.0</td>\n      <td>67.0</td>\n      <td>0.400107</td>\n      <td>-0.863984</td>\n      <td>0</td>\n      <td>0</td>\n      <td>34.465692</td>\n      <td>27.131783</td>\n      <td>12.094943</td>\n      <td>52.631579</td>\n      <td>22.1875</td>\n      <td>0.525633</td>\n      <td>-1.579696</td>\n      <td>2.37</td>\n      <td>71.0</td>\n      <td>3.2</td>\n      <td>71.0</td>\n      <td>2.72</td>\n      <td>70.0</td>\n      <td>2.83</td>\n      <td>73.0</td>\n      <td>1.59</td>\n      <td>76.0</td>\n      <td>2.77</td>\n      <td>67.0</td>\n      <td>1.52</td>\n      <td>80.0</td>\n      <td>1.59</td>\n      <td>78.0</td>\n      <td>1.53</td>\n      <td>74.0</td>\n      <td>2.55</td>\n      <td>67.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>70.0</td>\n      <td>2.58</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>71.9808</td>\n      <td>1</td>\n      <td>15.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>21.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>29.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>82.331088</td>\n      <td>82.0</td>\n      <td>8.807722</td>\n      <td>100.0</td>\n      <td>57.0</td>\n      <td>-0.061393</td>\n      <td>-0.577691</td>\n      <td>39.139228</td>\n      <td>32.941176</td>\n      <td>13.403911</td>\n      <td>65.789474</td>\n      <td>17.8125</td>\n      <td>0.534961</td>\n      <td>-1.262051</td>\n      <td>1.000000</td>\n      <td>1.014286</td>\n      <td>0.958904</td>\n      <td>0.960526</td>\n      <td>1.134328</td>\n      <td>0.837500</td>\n      <td>1.025641</td>\n      <td>1.054054</td>\n      <td>1.104478</td>\n      <td>NaN</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>11.0</td>\n      <td>18</td>\n      <td>2.73</td>\n      <td>0.33</td>\n      <td>5</td>\n      <td>81.090909</td>\n      <td>79.0</td>\n      <td>9.278519</td>\n      <td>98.0</td>\n      <td>67.0</td>\n      <td>0.391559</td>\n      <td>-0.752433</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38.983752</td>\n      <td>31.645570</td>\n      <td>15.405873</td>\n      <td>64.473684</td>\n      <td>20.9375</td>\n      <td>0.568460</td>\n      <td>-1.303589</td>\n      <td>2.37</td>\n      <td>75.0</td>\n      <td>3.2</td>\n      <td>67.0</td>\n      <td>2.72</td>\n      <td>76.0</td>\n      <td>2.83</td>\n      <td>73.0</td>\n      <td>1.59</td>\n      <td>79.0</td>\n      <td>2.77</td>\n      <td>84.0</td>\n      <td>1.52</td>\n      <td>98.0</td>\n      <td>1.59</td>\n      <td>93.0</td>\n      <td>1.53</td>\n      <td>88.0</td>\n      <td>2.55</td>\n      <td>84.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>75.0</td>\n      <td>2.58</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>79.7308</td>\n      <td>1</td>\n      <td>15.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>21.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>29.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>82.331088</td>\n      <td>82.0</td>\n      <td>8.807722</td>\n      <td>100.0</td>\n      <td>57.0</td>\n      <td>-0.061393</td>\n      <td>-0.577691</td>\n      <td>39.139228</td>\n      <td>32.941176</td>\n      <td>13.403911</td>\n      <td>65.789474</td>\n      <td>17.8125</td>\n      <td>0.534961</td>\n      <td>-1.262051</td>\n      <td>1.119403</td>\n      <td>0.881579</td>\n      <td>1.041096</td>\n      <td>0.924051</td>\n      <td>0.940476</td>\n      <td>0.857143</td>\n      <td>1.053763</td>\n      <td>1.056818</td>\n      <td>1.047619</td>\n      <td>NaN</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>11.0</td>\n      <td>18</td>\n      <td>2.73</td>\n      <td>0.33</td>\n      <td>5</td>\n      <td>81.545455</td>\n      <td>84.0</td>\n      <td>5.820028</td>\n      <td>88.0</td>\n      <td>72.0</td>\n      <td>-0.458629</td>\n      <td>-1.321737</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38.434065</td>\n      <td>34.108527</td>\n      <td>12.201636</td>\n      <td>55.921053</td>\n      <td>24.6875</td>\n      <td>0.413199</td>\n      <td>-1.523667</td>\n      <td>2.37</td>\n      <td>86.0</td>\n      <td>3.2</td>\n      <td>79.0</td>\n      <td>2.72</td>\n      <td>87.0</td>\n      <td>2.83</td>\n      <td>80.0</td>\n      <td>1.59</td>\n      <td>87.0</td>\n      <td>2.77</td>\n      <td>74.0</td>\n      <td>1.52</td>\n      <td>85.0</td>\n      <td>1.59</td>\n      <td>84.0</td>\n      <td>1.53</td>\n      <td>75.0</td>\n      <td>2.55</td>\n      <td>72.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>88.0</td>\n      <td>2.58</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>80.5608</td>\n      <td>0</td>\n      <td>15.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>21.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>29.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>82.331088</td>\n      <td>82.0</td>\n      <td>8.807722</td>\n      <td>100.0</td>\n      <td>57.0</td>\n      <td>-0.061393</td>\n      <td>-0.577691</td>\n      <td>39.139228</td>\n      <td>32.941176</td>\n      <td>13.403911</td>\n      <td>65.789474</td>\n      <td>17.8125</td>\n      <td>0.534961</td>\n      <td>-1.262051</td>\n      <td>1.088608</td>\n      <td>0.908046</td>\n      <td>1.087500</td>\n      <td>0.919540</td>\n      <td>1.175676</td>\n      <td>0.870588</td>\n      <td>1.011905</td>\n      <td>1.120000</td>\n      <td>1.041667</td>\n      <td>NaN</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>11.0</td>\n      <td>18</td>\n      <td>2.73</td>\n      <td>0.33</td>\n      <td>5</td>\n      <td>83.818182</td>\n      <td>82.0</td>\n      <td>5.231026</td>\n      <td>95.0</td>\n      <td>78.0</td>\n      <td>1.158660</td>\n      <td>0.224593</td>\n      <td>0</td>\n      <td>0</td>\n      <td>39.894798</td>\n      <td>31.782946</td>\n      <td>14.099267</td>\n      <td>62.500000</td>\n      <td>24.3750</td>\n      <td>0.553162</td>\n      <td>-1.442611</td>\n      <td>2.37</td>\n      <td>81.0</td>\n      <td>3.2</td>\n      <td>78.0</td>\n      <td>2.72</td>\n      <td>82.0</td>\n      <td>2.83</td>\n      <td>83.0</td>\n      <td>1.59</td>\n      <td>84.0</td>\n      <td>2.77</td>\n      <td>79.0</td>\n      <td>1.52</td>\n      <td>95.0</td>\n      <td>1.59</td>\n      <td>92.0</td>\n      <td>1.53</td>\n      <td>85.0</td>\n      <td>2.55</td>\n      <td>81.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>82.0</td>\n      <td>2.58</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>83.3308</td>\n      <td>2</td>\n      <td>15.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>21.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>29.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>82.331088</td>\n      <td>82.0</td>\n      <td>8.807722</td>\n      <td>100.0</td>\n      <td>57.0</td>\n      <td>-0.061393</td>\n      <td>-0.577691</td>\n      <td>39.139228</td>\n      <td>32.941176</td>\n      <td>13.403911</td>\n      <td>65.789474</td>\n      <td>17.8125</td>\n      <td>0.534961</td>\n      <td>-1.262051</td>\n      <td>1.038462</td>\n      <td>0.951220</td>\n      <td>0.987952</td>\n      <td>0.988095</td>\n      <td>1.063291</td>\n      <td>0.831579</td>\n      <td>1.032609</td>\n      <td>1.082353</td>\n      <td>1.049383</td>\n      <td>NaN</td>\n      <td>83.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>11.0</td>\n      <td>18</td>\n      <td>2.73</td>\n      <td>0.33</td>\n      <td>5</td>\n      <td>77.818182</td>\n      <td>77.0</td>\n      <td>5.153992</td>\n      <td>87.0</td>\n      <td>71.0</td>\n      <td>0.564558</td>\n      <td>-0.629030</td>\n      <td>0</td>\n      <td>0</td>\n      <td>37.087428</td>\n      <td>30.980392</td>\n      <td>13.230685</td>\n      <td>57.236842</td>\n      <td>22.5000</td>\n      <td>0.506874</td>\n      <td>-1.510406</td>\n      <td>2.37</td>\n      <td>75.0</td>\n      <td>3.2</td>\n      <td>72.0</td>\n      <td>2.72</td>\n      <td>74.0</td>\n      <td>2.83</td>\n      <td>76.0</td>\n      <td>1.59</td>\n      <td>79.0</td>\n      <td>2.77</td>\n      <td>71.0</td>\n      <td>1.52</td>\n      <td>87.0</td>\n      <td>1.59</td>\n      <td>86.0</td>\n      <td>1.53</td>\n      <td>80.0</td>\n      <td>2.55</td>\n      <td>79.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>77.0</td>\n      <td>2.58</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>76.8608</td>\n      <td>2</td>\n      <td>15.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>21.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>29.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>82.331088</td>\n      <td>82.0</td>\n      <td>8.807722</td>\n      <td>100.0</td>\n      <td>57.0</td>\n      <td>-0.061393</td>\n      <td>-0.577691</td>\n      <td>39.139228</td>\n      <td>32.941176</td>\n      <td>13.403911</td>\n      <td>65.789474</td>\n      <td>17.8125</td>\n      <td>0.534961</td>\n      <td>-1.262051</td>\n      <td>1.041667</td>\n      <td>0.972973</td>\n      <td>0.973684</td>\n      <td>0.962025</td>\n      <td>1.112676</td>\n      <td>0.816092</td>\n      <td>1.011628</td>\n      <td>1.075000</td>\n      <td>1.012658</td>\n      <td>NaN</td>\n      <td>77.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "   gender  exam_time  knowledge_cnt  hardvalue_sum  hardvalue_max hardvalue_rank  score_mean  score_median  score_std  score_max  score_min  score_skew  score_kurtosis  le_course  le_course_class  effotvalue_mean  effotvalue_median  effotvalue_std  effotvalue_max  effotvalue_min  effotvalue_skew  effotvalue_kurtosis  last_hard1  last_exam1  last_hard2  last_exam2  last_hard3  last_exam3  last_hard4  last_exam4  last_hard5  last_exam5  last_hard6  last_exam6  last_hard7  last_exam7  last_hard8  last_exam8  last_hard9  last_exam9  last_hard10  last_exam10  last_hard11  last_exam11  last_exam_midterm  last_hard_midterm  last_exam_final  last_hard_final  last_exam_final2  last_hard_final2  last_exam_final3  last_hard_final3  last_exam_final4  last_hard_final4  section_count  pred_score  his_zero_cnt  section_score1  section_score2  section_score3  section_score4  section_score5  section_score6  section_score7  section_score8  section_score9  section_score10  section_score11  \\\n0       0       11.0             18           2.73           0.33              5   72.454545          71.0   4.227615       80.0       67.0    0.400107       -0.863984          0                0        34.465692          27.131783       12.094943       52.631579         22.1875         0.525633            -1.579696        2.37        71.0         3.2        71.0        2.72        70.0        2.83        73.0        1.59        76.0        2.77        67.0        1.52        80.0        1.59        78.0        1.53        74.0         2.55         67.0          NaN          NaN               70.0               2.58              NaN              NaN               NaN               NaN               NaN               NaN               NaN               NaN             11     71.9808             1            15.0             7.0             6.0            21.0             7.0             7.0             5.0            29.0             3.0              NaN              NaN   \n1       0       11.0             18           2.73           0.33              5   81.090909          79.0   9.278519       98.0       67.0    0.391559       -0.752433          0                0        38.983752          31.645570       15.405873       64.473684         20.9375         0.568460            -1.303589        2.37        75.0         3.2        67.0        2.72        76.0        2.83        73.0        1.59        79.0        2.77        84.0        1.52        98.0        1.59        93.0        1.53        88.0         2.55         84.0          NaN          NaN               75.0               2.58              NaN              NaN               NaN               NaN               NaN               NaN               NaN               NaN             11     79.7308             1            15.0             7.0             6.0            21.0             7.0             7.0             5.0            29.0             3.0              NaN              NaN   \n2       0       11.0             18           2.73           0.33              5   81.545455          84.0   5.820028       88.0       72.0   -0.458629       -1.321737          0                0        38.434065          34.108527       12.201636       55.921053         24.6875         0.413199            -1.523667        2.37        86.0         3.2        79.0        2.72        87.0        2.83        80.0        1.59        87.0        2.77        74.0        1.52        85.0        1.59        84.0        1.53        75.0         2.55         72.0          NaN          NaN               88.0               2.58              NaN              NaN               NaN               NaN               NaN               NaN               NaN               NaN             11     80.5608             0            15.0             7.0             6.0            21.0             7.0             7.0             5.0            29.0             3.0              NaN              NaN   \n3       1       11.0             18           2.73           0.33              5   83.818182          82.0   5.231026       95.0       78.0    1.158660        0.224593          0                0        39.894798          31.782946       14.099267       62.500000         24.3750         0.553162            -1.442611        2.37        81.0         3.2        78.0        2.72        82.0        2.83        83.0        1.59        84.0        2.77        79.0        1.52        95.0        1.59        92.0        1.53        85.0         2.55         81.0          NaN          NaN               82.0               2.58              NaN              NaN               NaN               NaN               NaN               NaN               NaN               NaN             11     83.3308             2            15.0             7.0             6.0            21.0             7.0             7.0             5.0            29.0             3.0              NaN              NaN   \n4       0       11.0             18           2.73           0.33              5   77.818182          77.0   5.153992       87.0       71.0    0.564558       -0.629030          0                0        37.087428          30.980392       13.230685       57.236842         22.5000         0.506874            -1.510406        2.37        75.0         3.2        72.0        2.72        74.0        2.83        76.0        1.59        79.0        2.77        71.0        1.52        87.0        1.59        86.0        1.53        80.0         2.55         79.0          NaN          NaN               77.0               2.58              NaN              NaN               NaN               NaN               NaN               NaN               NaN               NaN             11     76.8608             2            15.0             7.0             6.0            21.0             7.0             7.0             5.0            29.0             3.0              NaN              NaN   \n\n   course_group_score_mean  course_group_score_median  course_group_score_std  course_group_score_max  course_group_score_min  course_group_score_skew  course_group_score_kurtosis  course_group_effotvalue_mean  course_group_effotvalue_median  course_group_effotvalue_std  course_group_effotvalue_max  course_group_effotvalue_min  course_group_effotvalue_skew  course_group_effotvalue_kurtosis  ratio_last_exam12  ratio_last_exam23  ratio_last_exam34  ratio_last_exam45  ratio_last_exam56  ratio_last_exam67  ratio_last_exam78  ratio_last_exam89  ratio_last_exam910  ratio_last_exam1011  score  \n0                82.331088                       82.0                8.807722                   100.0                    57.0                -0.061393                    -0.577691                     39.139228                       32.941176                    13.403911                    65.789474                      17.8125                      0.534961                         -1.262051           1.000000           1.014286           0.958904           0.960526           1.134328           0.837500           1.025641           1.054054            1.104478                  NaN   70.0  \n1                82.331088                       82.0                8.807722                   100.0                    57.0                -0.061393                    -0.577691                     39.139228                       32.941176                    13.403911                    65.789474                      17.8125                      0.534961                         -1.262051           1.119403           0.881579           1.041096           0.924051           0.940476           0.857143           1.053763           1.056818            1.047619                  NaN   75.0  \n2                82.331088                       82.0                8.807722                   100.0                    57.0                -0.061393                    -0.577691                     39.139228                       32.941176                    13.403911                    65.789474                      17.8125                      0.534961                         -1.262051           1.088608           0.908046           1.087500           0.919540           1.175676           0.870588           1.011905           1.120000            1.041667                  NaN   75.0  \n3                82.331088                       82.0                8.807722                   100.0                    57.0                -0.061393                    -0.577691                     39.139228                       32.941176                    13.403911                    65.789474                      17.8125                      0.534961                         -1.262051           1.038462           0.951220           0.987952           0.988095           1.063291           0.831579           1.032609           1.082353            1.049383                  NaN   83.0  \n4                82.331088                       82.0                8.807722                   100.0                    57.0                -0.061393                    -0.577691                     39.139228                       32.941176                    13.403911                    65.789474                      17.8125                      0.534961                         -1.262051           1.041667           0.972973           0.973684           0.962025           1.112676           0.816092           1.011628           1.075000            1.012658                  NaN   77.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final_temp = data_final.copy()\n",
    "data_final_temp = data_final_temp.loc[data_final_temp.score!=0] #包含0训练 6.55 7.39/ 不包含4.04 7.316\n",
    "le = LabelEncoder()\n",
    "data_final_temp[\"le_course\"] = le.fit_transform(data_final_temp[\"course\"])\n",
    "le = LabelEncoder()\n",
    "data_final_temp[\"le_course_class\"] = le.fit_transform(data_final_temp[\"course_class\"])\n",
    "le = LabelEncoder()\n",
    "data_final_temp[\"le_category\"] = le.fit_transform(data_final_temp[\"category\"])\n",
    "\n",
    "y = \"score\"\n",
    "\n",
    "features = [\"gender\",\"exam_time\",\"knowledge_cnt\"]\\\n",
    "           +[\"hardvalue_sum\",\"hardvalue_max\",\"hardvalue_rank\"] \\\n",
    "           + [i for i in data_final_temp.columns if i[:6] == \"score_\"] \\\n",
    "           +[\"le_course\",\"le_course_class\"] \\\n",
    "           + [i for i in data_final_temp.columns if i[:11]==\"effotvalue_\"] \\\n",
    "           + [i for i in data_final_temp.columns if i[:5]==\"last_\"] \\\n",
    "           + [\"section_count\",\"pred_score\",\"his_zero_cnt\"] \\\n",
    "          + [i for i in data_final_temp.columns if i[:9]==\"section_s\"]\\\n",
    "        + [i for i in data_final_temp.columns if \"course_group\" in i]\\\n",
    "        + [i for i in data_final_temp.columns if i[:6]==\"ratio_\"]\\\n",
    "\n",
    "print(features)\n",
    "print(len(features))\n",
    "categorical_feats = [\"le_course\",\"le_course_class\",\"gender\"]\n",
    "train = data_final_temp[data_final_temp.is_train==1]\n",
    "test = data_final_temp[data_final_temp.is_train==0]\n",
    "print(\"train shape:\",train.shape)\n",
    "print(\"test shape:\",test.shape)\n",
    "train[features+[y]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "FC99F0280368475A91DEE839514F74BA",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\nfeatures: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n  warnings.warn('Using categorical_feature in Dataset.')\n/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n[300]\ttraining's rmse: 2.40311\tvalid_1's rmse: 2.52885\n[600]\ttraining's rmse: 2.30549\tvalid_1's rmse: 2.51094\n[900]\ttraining's rmse: 2.23375\tvalid_1's rmse: 2.50658\nEarly stopping, best iteration is:\n[953]\ttraining's rmse: 2.22103\tvalid_1's rmse: 2.50545\nfold 1\nfeatures: 92\nTraining until validation scores don't improve for 100 rounds.\n[300]\ttraining's rmse: 2.40714\tvalid_1's rmse: 2.5132\n[600]\ttraining's rmse: 2.31216\tvalid_1's rmse: 2.49447\n[900]\ttraining's rmse: 2.24198\tvalid_1's rmse: 2.49135\nEarly stopping, best iteration is:\n[936]\ttraining's rmse: 2.23384\tvalid_1's rmse: 2.49041\nfold 2\nfeatures: 92\nTraining until validation scores don't improve for 100 rounds.\n[300]\ttraining's rmse: 2.41132\tvalid_1's rmse: 2.49743\n[600]\ttraining's rmse: 2.3176\tvalid_1's rmse: 2.48265\nEarly stopping, best iteration is:\n[714]\ttraining's rmse: 2.28882\tvalid_1's rmse: 2.48085\nfold 3\nfeatures: 92\nTraining until validation scores don't improve for 100 rounds.\n[300]\ttraining's rmse: 2.41225\tvalid_1's rmse: 2.49371\n[600]\ttraining's rmse: 2.32467\tvalid_1's rmse: 2.4775\n[900]\ttraining's rmse: 2.24895\tvalid_1's rmse: 2.47086\n[1200]\ttraining's rmse: 2.18526\tvalid_1's rmse: 2.46909\nEarly stopping, best iteration is:\n[1171]\ttraining's rmse: 2.19104\tvalid_1's rmse: 2.46888\nfold 4\nfeatures: 92\nTraining until validation scores don't improve for 100 rounds.\n[300]\ttraining's rmse: 2.40065\tvalid_1's rmse: 2.53939\n[600]\ttraining's rmse: 2.30377\tvalid_1's rmse: 2.52334\nEarly stopping, best iteration is:\n[681]\ttraining's rmse: 2.28104\tvalid_1's rmse: 2.52227\nrmse 2.493641748158397\ncv score: 3.96800 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n    </tr>\n    <tr>\n      <th>Feature</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>pred_score</th>\n      <td>1333.8</td>\n    </tr>\n    <tr>\n      <th>ratio_last_exam45</th>\n      <td>609.2</td>\n    </tr>\n    <tr>\n      <th>ratio_last_exam34</th>\n      <td>586.6</td>\n    </tr>\n    <tr>\n      <th>ratio_last_exam12</th>\n      <td>586.0</td>\n    </tr>\n    <tr>\n      <th>last_exam1</th>\n      <td>540.6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "                   importance\nFeature                      \npred_score             1333.8\nratio_last_exam45       609.2\nratio_last_exam34       586.6\nratio_last_exam12       586.0\nlast_exam1              540.6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=2333)\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "train_x = train[features]\n",
    "test_x = test[features]\n",
    "train_y = train[y]\n",
    "stack_metrix = np.array([len(train),5])\n",
    "param = {'objective': 'regression',\n",
    "         'num_leaves': 24, #2**5 32 3.983 28 3.980 29 3.979\n",
    "         'min_data_in_leaf': 25,#25\n",
    "         'max_depth': 5,  #5\n",
    "         'learning_rate': 0.02, #\n",
    "         'lambda_l1': 0.13,#0.13\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7,#0.7\n",
    "         'bagging_freq': 8,#8\n",
    "         \"bagging_fraction\": 0.9, #0.9\n",
    "         \"metric\": 'rmse',\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333,\n",
    "         \"num_threads\" : 50}\n",
    "# lgb\n",
    "model = \"lgb\"\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_x.values, train_y.values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    print(\"features:\",len(features))\n",
    "\n",
    "    trn_data = lgb.Dataset(train_x.iloc[trn_idx],\n",
    "                          label=train_y.iloc[trn_idx],\n",
    "                          categorical_feature=categorical_feats\n",
    "                          )\n",
    "    val_data = lgb.Dataset(train_x.iloc[val_idx],\n",
    "                          label=train_y.iloc[val_idx],\n",
    "                          categorical_feature=categorical_feats\n",
    "                          )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round\n",
    "                    , valid_sets=[trn_data, val_data]\n",
    "                    , verbose_eval=300\n",
    "                    ,early_stopping_rounds=100\n",
    "                    # ,feval=custom_mertic\n",
    "                    )\n",
    "\n",
    "    oof[val_idx] = clf.predict(train_x.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    predictions += clf.predict(test_x, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "feature_importance = feature_importance_df[[\"Feature\", \"importance\"]].groupby(\"Feature\").mean().sort_values(by=\"importance\",\n",
    "ascending=False)\n",
    "\n",
    "rmse = round(10*log10(mean_squared_error(train_y, oof)**0.5),3)\n",
    "\n",
    "print(\"rmse\",mean_squared_error(train_y, oof)**0.5)\n",
    "\n",
    "print(\"cv score: {:<8.5f}\".format(rmse))\n",
    "\n",
    "test[\"pred\"] = predictions\n",
    "\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3CD55C7ECD5F470B819749F44EA30FF5",
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student_id   course   exam_id  pred\n0      230748  course1  PcVABZEp   NaN\n1      186851  course1  PcVABZEp   NaN\n2      478370  course1  PcVABZEp   NaN\n3      692328  course1  PcVABZEp   NaN\n4      509128  course1  PcVABZEp   NaN\nresult_lgb_3.968.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>course</th>\n      <th>exam_id</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>230748</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>85.614003</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186851</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>79.305076</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>478370</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>82.770960</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>692328</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>79.647450</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>509128</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>79.999485</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "   student_id   course   exam_id       pred\n0      230748  course1  PcVABZEp  85.614003\n1      186851  course1  PcVABZEp  79.305076\n2      478370  course1  PcVABZEp  82.770960\n3      692328  course1  PcVABZEp  79.647450\n4      509128  course1  PcVABZEp  79.999485"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub =pd.read_csv(open(data_path+\"submission_s2.csv\",encoding='utf8'))\n",
    "print(sub.head())\n",
    "del sub[\"pred\"]\n",
    "sub = sub.merge(test[[\"student_id\", \"course\", \"exam_id\",\"pred\"]],how='left',on=[\"student_id\", \"course\", \"exam_id\"])\n",
    "name = \"result_{}_{}.csv\".format(model,rmse)\n",
    "print(name)\n",
    "sub.to_csv(out_path+name,index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "405116CE32B046EFB6923B66B62EFC26",
    "mdEditEnable": false
   },
   "source": [
    "# 模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "BF93957C5F5343FD9E0AE52D48346092",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>course</th>\n      <th>exam_id</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>230748</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>85.917620</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186851</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>80.418180</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>478370</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>82.426456</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>692328</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>80.513347</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>509128</td>\n      <td>course1</td>\n      <td>PcVABZEp</td>\n      <td>81.094846</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "   student_id   course   exam_id       pred\n0      230748  course1  PcVABZEp  85.917620\n1      186851  course1  PcVABZEp  80.418180\n2      478370  course1  PcVABZEp  82.426456\n3      692328  course1  PcVABZEp  80.513347\n4      509128  course1  PcVABZEp  81.094846"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = pd.read_csv(out_path+\"result_old_4.732.csv\") #\n",
    "model2 = pd.read_csv(out_path+name) #7.302\n",
    "model_out = model1.copy()\n",
    "model_out[\"pred\"] = 0.35*model1[\"pred\"]+0.65*model2[\"pred\"]\n",
    "model_out.to_csv(out_path+\"stack_3565.csv\",index=False)\n",
    "model_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "783AEF3F54B34E7AA95A2CBD3A0133A7",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: /opt/conda/lib/libcrypto.so.1.0.0: no version information available (required by wget)\nwget: /opt/conda/lib/libssl.so.1.0.0: no version information available (required by wget)\nwget: /opt/conda/lib/libssl.so.1.0.0: no version information available (required by wget)\n--2019-09-05 18:08:38--  https://cdn.kesci.com/submit_tool/v3/tianyi_submit\nResolving cdn.kesci.com (cdn.kesci.com)... 42.120.107.18, 42.120.107.17\nConnecting to cdn.kesci.com (cdn.kesci.com)|42.120.107.18|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 6709558 (6.4M) [application/x-executable]\nSaving to: ‘tianyi_submit’\n\ntianyi_submit       100%[===================>]   6.40M  --.-KB/s    in 0.1s    \n\n2019-09-05 18:08:38 (59.6 MB/s) - ‘tianyi_submit’ saved [6709558/6709558]\n\n"
     ]
    }
   ],
   "source": [
    "!wget -O tianyi_submit https://cdn.kesci.com/submit_tool/v3/tianyi_submit&&chmod +x tianyi_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6F69B984C29B471385CFF89E77D3ABE1",
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tianyi Submit Tool 3.2.1\n\n> 已验证Token\n> 提交文件 /home/kesci/work/out/stack_46.csv (163.44 KiB)\n> 已上传 100 %\n> 文件已上传        \n> 服务器响应: 200 提交成功，请等待评审完成\n> 提交完成\n"
     ]
    }
   ],
   "source": [
    "!./tianyi_submit -file /home/kesci/work/out/stack_46.csv -token 9f743b5e40d4520c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
